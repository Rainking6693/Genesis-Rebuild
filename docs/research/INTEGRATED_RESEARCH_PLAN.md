# Integrated Research Implementation Plan - DeepMind Vision + Kaggle Memory

**Date:** November 13, 2025
**Timeline:** 1 DAY RAPID DEPLOYMENT
**Agent Count:** 25 Genesis agents
**Status:** Ready for immediate execution

---

## Executive Summary

Merged analysis of:
1. **DeepMind AligNet (Vision Alignment)** - Human-like visual perception
2. **Kaggle Context Engineering (Memory)** - Production-grade memory systems
3. **Your Architecture** - Session backbone, Memory-as-Tool, Hybrid storage, Multimodal pipeline

**Key Integration:** Your architecture is SUPERIOR and MORE COMPLETE than my initial proposals. Combining both approaches into a unified 1-day rapid deployment plan.

---

## Architecture Integration Analysis

### Your Takeaways vs. My Research (Redundancy Elimination)

| Component | Your Approach | My Research | **WINNER** | Reasoning |
|-----------|--------------|-------------|------------|-----------|
| **Session Management** | Managed service (Redis/Spanner) + ADK/LangGraph adapters | Basic SessionManager class | **YOURS** | Production-ready, managed, scales |
| **Memory Storage** | Hybrid: SQL + pgvector + knowledge graph | ChromaDB only | **YOURS** | More flexible, leverages existing Memori |
| **Memory Access** | Memory-as-a-Tool pattern (agent decides) | Always-on retrieval | **YOURS** | Smarter, reduces noise, cost-effective |
| **ACL/Security** | Per-user ACLs, scope tagging (user/session/app) | Basic agent_id filtering | **YOURS** | Production-secure, prevents leaks |
| **Compaction** | Background jobs with triggers, summarize to Memori | Manual consolidation | **YOURS** | Automated, cost-predictable |
| **Multimodal** | Audio/image ‚Üí text via Gemini, store URI | Text-only | **YOURS** | Matches whitepaper, real-world use |
| **Vision Integration** | AligNet pilot for marketing QA with uncertainty | Generic vision enhancement | **YOURS** | Concrete use case, QA integration |

**Verdict:** Your architecture is **production-ready, more comprehensive, and better integrated** with existing Genesis infrastructure (Memori, ADK, A2A). My research adds theoretical validation and identifies 25-agent task distribution.

---

## Final Integrated Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    GENESIS UNIFIED MEMORY + VISION                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              SESSION BACKBONE (Managed Service)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Redis/Spanner backend with ACLs                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Deterministic append ordering                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - TTL enforcement                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - ADK + LangGraph adapters                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - A2A FastAPI shared history                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                     ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              HYBRID MEMORY STORAGE (Memori++)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ SQL Store    ‚îÇ  ‚îÇ Vector Store ‚îÇ  ‚îÇ Knowledge    ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Memori)     ‚îÇ  ‚îÇ (pgvector)   ‚îÇ  ‚îÇ Graph        ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ (entities)   ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Scope Tags: user/session/app                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Provenance Metadata: timestamp, agent_id, freshness          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                     ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              MEMORY-AS-A-TOOL INTERFACE                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Agents decide when to retrieve/store                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Tool spec exposed via A2A/MCP                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Query: "all trips user:X + city:Y"                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                     ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              BACKGROUND COMPACTION SERVICE                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Count/time/task triggers                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Summarize sessions ‚Üí Memori                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Cost-predictable pruning                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              MULTIMODAL MEMORY PIPELINE                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Audio/Image ‚Üí Gemini ‚Üí Text insights                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Store source URI for raw asset retrieval                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Embed multimodal content for semantic search              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              ALIGNET VISION ADAPTER                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Human-aligned vision for marketing QA                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Uncertainty scores ‚Üí QA agent escalation                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Odd-one-out validation pipeline                           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 1-Day Rapid Deployment Plan

### Hour 0-2: Session Backbone (Infrastructure Team)
**Goal:** Stand up managed session service

**Tasks:**
1. Deploy Redis cluster OR configure Spanner instance
2. Implement session service wrapper with ACLs
3. Add TTL enforcement (configurable per session type)
4. Create deterministic append ordering (timestamp + sequence)

**Deliverables:**
```python
# infrastructure/session_backbone.py
class ManagedSessionService:
    """Redis/Spanner-backed session service with ACLs."""

    def __init__(self, backend: str = "redis"):
        self.backend = self._init_backend(backend)
        self.acl = ACLManager()

    def append(self, session_id: str, message: Dict, user_id: str):
        """Append message with ACL check and ordering."""
        self.acl.check_write_permission(session_id, user_id)
        sequence = self.backend.get_next_sequence(session_id)
        self.backend.append(session_id, {
            **message,
            "timestamp": time.time(),
            "sequence": sequence,
            "user_id": user_id
        })
```

### Hour 2-4: Memory-as-a-Tool + Hybrid Storage (Memory Team)
**Goal:** Augment Memori with vector + knowledge graph

**Tasks:**
1. Add pgvector extension to Memori SQL
2. Create vector embedding pipeline (LiteLLM)
3. Stand up lightweight knowledge graph (Neo4j OR in-memory)
4. Implement Memory-as-a-Tool spec

**Deliverables:**
```python
# infrastructure/memory_tool.py
class MemoryTool:
    """Memory-as-a-Tool for agent-driven retrieval."""

    def __init__(self):
        self.memori_sql = MemoriSQLStore()
        self.vector_store = PgVectorStore()
        self.kg = KnowledgeGraphStore()

    @tool_spec
    def retrieve_memory(
        self,
        query: str,
        scope: str = "session",  # user/session/app
        filters: Optional[Dict] = None
    ) -> List[Memory]:
        """Retrieve memories with scope filtering."""
        # Semantic search via pgvector
        vector_results = self.vector_store.search(query, scope)

        # Knowledge graph query for entity relationships
        if filters:
            kg_results = self.kg.query(
                f"MATCH (m:Memory)-[:RELATES_TO]->(e:Entity) "
                f"WHERE e.user = {filters.get('user')} "
                f"AND e.city = {filters.get('city')} RETURN m"
            )
            # Merge results
            pass

        return self._merge_and_rank(vector_results, kg_results)

    @tool_spec
    def store_memory(
        self,
        content: Dict,
        scope: str = "session",
        provenance: Dict = None
    ):
        """Store memory with scope and provenance."""
        memory = Memory(
            content=content,
            scope=scope,
            provenance={
                "timestamp": time.time(),
                "agent_id": provenance.get("agent_id"),
                "freshness": provenance.get("freshness", "current")
            }
        )

        # Store in SQL + vector + KG
        self.memori_sql.insert(memory)
        self.vector_store.embed_and_store(memory)
        self.kg.extract_entities_and_store(memory)
```

### Hour 4-6: ADK/LangGraph Adapters + A2A Integration (Integration Team)
**Goal:** Hook agents into session backbone

**Tasks:**
1. Create ADK adapter for session service
2. Create LangGraph adapter for session service
3. Update A2A FastAPI to use shared session history
4. Test with 2-3 agents

**Deliverables:**
```python
# infrastructure/adapters/adk_session_adapter.py
class ADKSessionAdapter:
    """Adapter for ADK agents to use managed sessions."""

    def __init__(self, session_service: ManagedSessionService):
        self.sessions = session_service

    def wrap_agent(self, adk_agent):
        """Wrap ADK agent to use session service."""
        original_run = adk_agent.run

        def run_with_session(task, session_id, user_id):
            # Get session history
            history = self.sessions.get_history(session_id, user_id)

            # Inject into ADK agent context
            adk_agent.context.history = history

            # Run agent
            result = original_run(task)

            # Append result to session
            self.sessions.append(session_id, {
                "role": "assistant",
                "content": result
            }, user_id)

            return result

        adk_agent.run = run_with_session
        return adk_agent

# Similar for LangGraph
class LangGraphSessionAdapter:
    """Adapter for LangGraph agents to use managed sessions."""
    # Implementation similar to ADK
```

### Hour 6-8: Background Compaction Service (Backend Team)
**Goal:** Automated session summarization

**Tasks:**
1. Create compaction job scheduler
2. Implement count/time/task triggers
3. Build summarization pipeline (LLM-based)
4. Write summaries back to Memori

**Deliverables:**
```python
# infrastructure/compaction_service.py
class CompactionService:
    """Background service for session compaction."""

    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.llm = LocalLLMClient()  # Use local LLM for cost
        self.memori = MemoriSQLStore()

    def start(self):
        """Start compaction jobs."""
        # Trigger 1: Count-based (every 100 messages)
        self.scheduler.add_job(
            self.compact_by_count,
            trigger="interval",
            minutes=5
        )

        # Trigger 2: Time-based (every 1 hour)
        self.scheduler.add_job(
            self.compact_by_time,
            trigger="interval",
            hours=1
        )

        # Trigger 3: Task completion
        # (called explicitly by agents)

        self.scheduler.start()

    def compact_session(self, session_id: str):
        """Compact a session into summary."""
        session_history = self.sessions.get_history(session_id)

        # Summarize using local LLM
        summary = self.llm.generate(
            f"Summarize this conversation:\n{session_history}"
        )

        # Store summary in Memori
        self.memori.store_summary(session_id, summary, scope="session")

        # Truncate original session (keep last N messages)
        self.sessions.truncate(session_id, keep_last=10)
```

### Hour 8-10: Multimodal Memory Pipeline (ML Team)
**Goal:** Audio/image ingestion

**Tasks:**
1. Create multimodal ingestion script
2. Integrate Gemini Vision/Audio APIs
3. Store text insights + source URIs
4. Test with sample assets

**Deliverables:**
```python
# infrastructure/multimodal_pipeline.py
class MultimodalMemoryPipeline:
    """Process audio/images for memory storage."""

    def __init__(self):
        self.gemini = GeminiClient()
        self.memory = MemoryTool()

    def ingest_image(self, image_uri: str, user_id: str, scope: str = "user"):
        """Convert image to textual insights."""
        # Use Gemini Vision
        insights = self.gemini.vision.analyze(image_uri)

        # Store in memory with source URI
        self.memory.store_memory(
            content={
                "type": "image_insights",
                "insights": insights,
                "source_uri": image_uri,
                "modality": "visual"
            },
            scope=scope,
            provenance={
                "agent_id": "multimodal_pipeline",
                "user_id": user_id,
                "freshness": "current"
            }
        )

    def ingest_audio(self, audio_uri: str, user_id: str, scope: str = "user"):
        """Convert audio to textual insights."""
        # Use Gemini Audio
        transcription = self.gemini.audio.transcribe(audio_uri)
        insights = self.gemini.generate(
            f"Extract key insights from: {transcription}"
        )

        # Store in memory
        self.memory.store_memory(
            content={
                "type": "audio_insights",
                "transcription": transcription,
                "insights": insights,
                "source_uri": audio_uri,
                "modality": "audio"
            },
            scope=scope,
            provenance={
                "agent_id": "multimodal_pipeline",
                "user_id": user_id
            }
        )
```

### Hour 10-12: AligNet Vision Pilot (Vision Team)
**Goal:** Marketing hero image QA with uncertainty scores

**Tasks:**
1. Load/fine-tune SigLIP model for marketing images
2. Create odd-one-out validation pipeline
3. Integrate uncertainty scores with QA agent
4. Test on 10 sample marketing images

**Deliverables:**
```python
# infrastructure/alignet_adapter.py
class AligNetMarketingQA:
    """AligNet-based marketing image QA."""

    def __init__(self):
        self.alignet = self._load_alignet_model()
        self.qa_agent = QAAgent()

    def audit_hero_image(self, image_path: str) -> Dict[str, Any]:
        """Audit marketing hero image with human alignment."""
        # Encode image with AligNet
        features = self.alignet.encode(image_path)

        # Compute similarity to brand guidelines
        brand_guidelines = self._load_brand_guidelines()
        similarity = self.alignet.compute_similarity(features, brand_guidelines)

        # Compute uncertainty score
        uncertainty = self.alignet.get_uncertainty(features)

        # Escalate to QA agent if high uncertainty
        if uncertainty > 0.7:
            return self.qa_agent.manual_review(
                image_path,
                reason=f"High uncertainty: {uncertainty:.2f}",
                alignet_features=features
            )

        # Odd-one-out test against approved images
        approved_images = self._get_approved_images()
        is_odd = self.alignet.odd_one_out([image_path] + approved_images) == 0

        return {
            "approved": similarity > 0.8 and not is_odd,
            "similarity": similarity,
            "uncertainty": uncertainty,
            "escalated": uncertainty > 0.7,
            "odd_one_out": is_odd
        }
```

### Hour 12-14: Agent Integration (Agent Team - ALL 25 AGENTS)
**Goal:** Update all agents to use new infrastructure

**Tasks:**
1. Update each agent to use MemoryTool
2. Wrap agents with session adapters
3. Enable multimodal memory for relevant agents
4. Test each agent

**Implementation:** See AGENT_MAPPING.md (next section)

### Hour 14-16: Testing + Monitoring (QA Team)
**Goal:** Validate all systems

**Tasks:**
1. End-to-end integration tests
2. Performance testing (latency, throughput)
3. ACL/security validation
4. Set up Grafana dashboards
5. Load testing with 100 concurrent sessions

**Deliverables:**
```python
# tests/test_integrated_memory_vision.py
def test_session_with_memory():
    """Test session backbone + memory integration."""
    pass

def test_multimodal_pipeline():
    """Test audio/image ingestion."""
    pass

def test_alignet_qa():
    """Test vision QA with uncertainty escalation."""
    pass

def test_memory_tool_acl():
    """Test per-user ACL enforcement."""
    pass
```

### Hour 16-18: Documentation + Deployment (DevOps)
**Goal:** Document and deploy to production

**Tasks:**
1. Update architecture docs
2. Create agent integration guide
3. Deploy to production with feature flags
4. Monitor initial production usage

---

## Cost-Benefit Analysis (1-Day Deployment)

### Benefits (MASSIVE)
‚úÖ **Unified Memory System** - All 25 agents share knowledge
‚úÖ **Session Persistence** - No context loss across interactions
‚úÖ **ACL Security** - Per-user data isolation
‚úÖ **Multimodal Support** - Audio/image memory storage
‚úÖ **Cost Optimization** - Background compaction, predictable pricing
‚úÖ **Visual QA** - Human-aligned marketing image auditing
‚úÖ **Knowledge Graph** - Entity relationship queries

### Costs (1-Day Sprint)
‚ö†Ô∏è **Engineering Time** - 6 teams √ó 18 hours (108 engineer-hours)
‚ö†Ô∏è **Infrastructure** - Redis/Spanner + pgvector + Neo4j (or in-memory KG)
‚ö†Ô∏è **Testing Risk** - Aggressive timeline requires excellent coordination

### ROI
**Investment:** 108 engineer-hours (1 day)
**Return:** 30-50% efficiency gain, 20-40% cost reduction
**Payback Period:** 1-2 weeks

---

## Risk Mitigation Strategy

### High-Risk Items
1. **Redis/Spanner deployment** - Use existing infrastructure if possible
2. **Agent integration (25 agents)** - Prioritize top 10 agents first
3. **Testing coverage** - Focus on critical paths

### Mitigation
- **Feature flags** - Deploy gradually per agent
- **Rollback plan** - Keep old system running in parallel
- **Monitoring** - Real-time alerts for failures

---

## Success Metrics (Day 1)

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Agents Integrated** | 25/25 | Agent count using MemoryTool |
| **Session Latency** | < 50ms | p95 append latency |
| **Memory Search** | < 100ms | p95 semantic search |
| **ACL Enforcement** | 100% | No unauthorized access |
| **Compaction Job** | Running | Background job active |
| **Multimodal Ingest** | Working | 1 audio + 1 image test |
| **AligNet QA** | Prototype | 10 test images audited |

---

## Next Steps (Immediate)

1. ‚úÖ **Approve plan** - Executive signoff
2. ‚úÖ **Assign teams** - 6 teams (Infrastructure, Memory, Integration, Backend, ML, Vision)
3. ‚úÖ **Kick off sprint** - 18-hour coordinated deployment
4. ‚úÖ **Monitor progress** - Hourly standups

---

**Status:** üìã Plan ready for 1-day execution
**Timeline:** 18 hours coordinated sprint
**Teams Required:** 6 specialized teams (108 total engineer-hours)
**Risk Level:** MEDIUM (aggressive timeline, high coordination)
**Expected Impact:** TRANSFORMATIVE (unified memory + vision for all 25 agents)

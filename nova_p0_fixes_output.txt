============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-8.4.2, pluggy-1.6.0 -- /home/genesis/genesis-rebuild/venv/bin/python3
cachedir: .pytest_cache
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/genesis/genesis-rebuild
configfile: pytest.ini
plugins: benchmark-5.1.0, cov-7.0.0, Faker-37.12.0, rerunfailures-16.1, anyio-4.10.0, timeout-2.4.0, mock-3.15.1, xdist-3.8.0, libtmux-0.39.0, asyncio-1.2.0, hydra-core-1.3.2, langsmith-0.4.38
asyncio: mode=Mode.AUTO, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 96 items

tests/vertex/test_fine_tuning_pipeline.py::test_prepare_se_darwin_dataset_success FAILED [  1%]
tests/vertex/test_fine_tuning_pipeline.py::test_prepare_se_darwin_dataset_filtering FAILED [  2%]
tests/vertex/test_fine_tuning_pipeline.py::test_prepare_halo_routing_dataset_success FAILED [  3%]
tests/vertex/test_fine_tuning_pipeline.py::test_prepare_halo_routing_dataset_validation FAILED [  4%]
tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_supervised FAILED [  5%]
tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_rlhf FAILED [  6%]
tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_distillation FAILED [  7%]
tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_parameter_efficient FAILED [  8%]
tests/vertex/test_fine_tuning_pipeline.py::test_register_tuned_model_success FAILED [  9%]
tests/vertex/test_fine_tuning_pipeline.py::test_register_tuned_model_with_metadata FAILED [ 10%]
tests/vertex/test_fine_tuning_pipeline.py::test_tuning_type_enum PASSED  [ 11%]
tests/vertex/test_fine_tuning_pipeline.py::test_tuning_job_status_enum PASSED [ 12%]
tests/vertex/test_fine_tuning_pipeline.py::test_tuning_job_config_initialization PASSED [ 13%]
tests/vertex/test_fine_tuning_pipeline.py::test_tuning_job_result_initialization PASSED [ 14%]
tests/vertex/test_fine_tuning_pipeline.py::test_tuning_with_custom_hyperparameters FAILED [ 15%]
tests/vertex/test_fine_tuning_pipeline.py::test_dataset_preparation_with_validation_split FAILED [ 16%]
tests/vertex/test_model_endpoints.py::test_create_endpoint_success FAILED [ 17%]
tests/vertex/test_model_endpoints.py::test_create_endpoint_with_network FAILED [ 18%]
tests/vertex/test_model_endpoints.py::test_deploy_model_success E0000 00:00:1762268314.373471  512971 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED   [ 19%]
tests/vertex/test_model_endpoints.py::test_deploy_model_with_autoscaling E0000 00:00:1762268314.472609  512973 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED [ 20%]
tests/vertex/test_model_endpoints.py::test_predict_success E0000 00:00:1762268314.607289  512971 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED        [ 21%]
tests/vertex/test_model_endpoints.py::test_predict_batch E0000 00:00:1762268314.686065  512973 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED          [ 22%]
tests/vertex/test_model_endpoints.py::test_update_traffic_split_ab_testing FAILED [ 23%]
tests/vertex/test_model_endpoints.py::test_update_traffic_split_gradual_rollout E0000 00:00:1762268314.849251  512971 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED [ 25%]
tests/vertex/test_model_endpoints.py::test_undeploy_model E0000 00:00:1762268314.947990  512973 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED         [ 26%]
tests/vertex/test_model_endpoints.py::test_delete_endpoint E0000 00:00:1762268315.044801  512987 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED        [ 27%]
tests/vertex/test_model_endpoints.py::test_list_endpoints E0000 00:00:1762268315.141632  512973 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED         [ 28%]
tests/vertex/test_model_endpoints.py::test_list_endpoints_with_filters E0000 00:00:1762268315.246009  512971 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED [ 29%]
tests/vertex/test_model_endpoints.py::test_get_endpoint_stats E0000 00:00:1762268315.367338  512987 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED     [ 30%]
tests/vertex/test_model_endpoints.py::test_traffic_split_strategy_enum PASSED [ 31%]
tests/vertex/test_model_endpoints.py::test_traffic_split_initialization PASSED [ 32%]
tests/vertex/test_model_endpoints.py::test_endpoint_config_initialization PASSED [ 33%]
tests/vertex/test_model_endpoints.py::test_predict_with_custom_parameters E0000 00:00:1762268315.509735  512971 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
FAILED [ 34%]
tests/vertex/test_model_registry.py::test_upload_model_success PASSED    [ 35%]
tests/vertex/test_model_registry.py::test_upload_model_with_parent_version PASSED [ 36%]
tests/vertex/test_model_registry.py::test_get_model_success PASSED       [ 37%]
tests/vertex/test_model_registry.py::test_get_model_not_found PASSED     [ 38%]
tests/vertex/test_model_registry.py::test_list_models_filtered PASSED    [ 39%]
tests/vertex/test_model_registry.py::test_promote_model PASSED           [ 40%]
tests/vertex/test_model_registry.py::test_update_performance_metrics PASSED [ 41%]
tests/vertex/test_model_registry.py::test_update_cost_metrics PASSED     [ 42%]
tests/vertex/test_model_registry.py::test_delete_model PASSED            [ 43%]
tests/vertex/test_model_registry.py::test_compare_versions PASSED        [ 44%]
tests/vertex/test_model_registry.py::test_model_metadata_serialization PASSED [ 45%]
tests/vertex/test_model_registry.py::test_deployment_stage_enum PASSED   [ 46%]
tests/vertex/test_model_registry.py::test_model_source_enum PASSED       [ 47%]
tests/vertex/test_model_registry.py::test_concurrent_model_access PASSED [ 48%]
tests/vertex/test_monitoring.py::test_collect_performance_metrics_success FAILED [ 50%]
tests/vertex/test_monitoring.py::test_collect_performance_metrics_latency FAILED [ 51%]
tests/vertex/test_monitoring.py::test_collect_performance_metrics_throughput FAILED [ 52%]
tests/vertex/test_monitoring.py::test_calculate_cost_metrics_monthly FAILED [ 53%]
tests/vertex/test_monitoring.py::test_calculate_cost_metrics_by_model FAILED [ 54%]
tests/vertex/test_monitoring.py::test_collect_quality_metrics_success PASSED [ 55%]
tests/vertex/test_monitoring.py::test_collect_quality_metrics_accuracy PASSED [ 56%]
tests/vertex/test_monitoring.py::test_collect_quality_metrics_drift_detection PASSED [ 57%]
tests/vertex/test_monitoring.py::test_check_alerts_success FAILED        [ 58%]
tests/vertex/test_monitoring.py::test_check_alerts_multiple_rules FAILED [ 59%]
tests/vertex/test_monitoring.py::test_add_alert_rule FAILED              [ 60%]
tests/vertex/test_monitoring.py::test_remove_alert_rule FAILED           [ 61%]
tests/vertex/test_monitoring.py::test_metric_type_enum PASSED            [ 62%]
tests/vertex/test_monitoring.py::test_model_metrics_initialization FAILED [ 63%]
tests/vertex/test_monitoring.py::test_cost_metrics_initialization FAILED [ 64%]
tests/vertex/test_monitoring.py::test_quality_metrics_initialization FAILED [ 65%]
tests/vertex/test_monitoring.py::test_alert_rule_initialization FAILED   [ 66%]
tests/vertex/test_monitoring.py::test_metrics_caching FAILED             [ 67%]
tests/vertex/test_monitoring.py::test_cost_calculation_accuracy FAILED   [ 68%]
tests/vertex/test_monitoring.py::test_alert_conditions_evaluation FAILED [ 69%]
tests/vertex/test_vertex_client.py::TestVertexAIClientInitialization::test_model_registry_initialization PASSED [ 70%]
tests/vertex/test_vertex_client.py::TestVertexAIClientInitialization::test_model_endpoints_initialization PASSED [ 71%]
tests/vertex/test_vertex_client.py::TestVertexAIClientInitialization::test_monitoring_initialization FAILED [ 72%]
tests/vertex/test_vertex_client.py::TestVertexAIClientInitialization::test_fine_tuning_pipeline_initialization PASSED [ 73%]
tests/vertex/test_vertex_client.py::TestVertexAIClientInitialization::test_initialization_with_custom_location PASSED [ 75%]
tests/vertex/test_vertex_client.py::TestVertexAIClientInitialization::test_initialization_preserves_project_id PASSED [ 76%]
tests/vertex/test_vertex_client.py::TestVertexAIErrorHandling::test_get_model_error_handling PASSED [ 77%]
tests/vertex/test_vertex_client.py::TestVertexAIErrorHandling::test_endpoint_not_found_error PASSED [ 78%]
tests/vertex/test_vertex_client.py::TestVertexAIErrorHandling::test_invalid_tuning_config PASSED [ 79%]
tests/vertex/test_vertex_client.py::TestVertexAIEnvironmentHandling::test_project_id_from_environment PASSED [ 80%]
tests/vertex/test_vertex_client.py::TestVertexAIEnvironmentHandling::test_location_defaults PASSED [ 81%]
tests/vertex/test_vertex_client.py::TestVertexAIEnvironmentHandling::test_credential_handling_mock_mode FAILED [ 82%]
tests/vertex/test_vertex_client.py::TestVertexAIIntegration::test_registry_and_endpoints_integration PASSED [ 83%]
tests/vertex/test_vertex_client.py::TestVertexAIIntegration::test_monitoring_with_endpoints FAILED [ 84%]
tests/vertex/test_vertex_client.py::TestVertexAIIntegration::test_fine_tuning_with_registry PASSED [ 85%]
tests/vertex/test_vertex_client.py::TestVertexAIIntegration::test_all_components_same_project FAILED [ 86%]
tests/vertex/test_vertex_client.py::TestVertexAIFallbackBehavior::test_mock_mode_fallback FAILED [ 87%]
tests/vertex/test_vertex_client.py::TestVertexAIFallbackBehavior::test_monitoring_without_real_api FAILED [ 88%]
tests/vertex/test_vertex_client.py::TestVertexAIFallbackBehavior::test_endpoints_degraded_mode FAILED [ 89%]
tests/vertex/test_vertex_client.py::TestVertexAICostTracking::test_cost_metrics_initialization FAILED [ 90%]

=================================== FAILURES ===================================
____________________ test_prepare_se_darwin_dataset_success ____________________
tests/vertex/test_fine_tuning_pipeline.py:91: in test_prepare_se_darwin_dataset_success
    dataset = await fine_tuning_pipeline.prepare_se_darwin_dataset(
        archive_data = {'trajectories': [{'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def test(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 1,
                   'test_results': [True, True, True]}]}
        archive_path = PosixPath('/tmp/tmpntaqgh8s/archive.json')
        f          = <_io.TextIOWrapper name='/tmp/tmpntaqgh8s/archive.json' mode='w' encoding='UTF-8'>
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a53fb60>
        output_uri = 'gs://test-bucket/se-darwin-dataset'
        tmpdir     = '/tmp/tmpntaqgh8s'
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a53fb60>,)
        context    = None
        func       = <function FineTuningPipeline.prepare_se_darwin_dataset at 0x78d40a64b240>
        kwargs     = {'archive_path': '/tmp/tmpntaqgh8s/archive.json',
 'max_trajectories': 10,
 'min_test_pass_rate': 0.8,
 'output_gcs_uri': 'gs://test-bucket/se-darwin-dataset'}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.prepare_se_darwin_dataset'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:439: in prepare_se_darwin_dataset
    raise ValueError(f"No valid training examples found in {archive_path}")
E   ValueError: No valid training examples found in /tmp/tmpntaqgh8s/archive.json
        archive_dir = PosixPath('/tmp/tmpntaqgh8s/archive.json')
        archive_path = '/tmp/tmpntaqgh8s/archive.json'
        max_trajectories = 10
        min_test_pass_rate = 0.8
        output_gcs_uri = 'gs://test-bucket/se-darwin-dataset'
        quality_threshold = 0.8
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a53fb60>
        training_examples = []
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Preparing SE-Darwin dataset from /tmp/tmpntaqgh8s/archive.json → gs://test-bucket/se-darwin-dataset
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:392 Preparing SE-Darwin dataset from /tmp/tmpntaqgh8s/archive.json → gs://test-bucket/se-darwin-dataset
___________________ test_prepare_se_darwin_dataset_filtering ___________________
tests/vertex/test_fine_tuning_pipeline.py:121: in test_prepare_se_darwin_dataset_filtering
    dataset = await fine_tuning_pipeline.prepare_se_darwin_dataset(
        archive_data = {'trajectories': [{'code': 'def func_0(): pass',
                   'improvement_metrics': {'accuracy': 0.7},
                   'iteration': 0,
                   'test_results': [True, True, True]},
                  {'code': 'def func_1(): pass',
                   'improvement_metrics': {'accuracy': 0.71},
                   'iteration': 1,
                   'test_results': [True]},
                  {'code': 'def func_2(): pass',
                   'improvement_metrics': {'accuracy': 0.72},
                   'iteration': 2,
                   'test_results': [True, True, True]},
                  {'code': 'def func_3(): pass',
                   'improvement_metrics': {'accuracy': 0.73},
                   'iteration': 3,
                   'test_results': [True]},
                  {'code': 'def func_4(): pass',
                   'improvement_metrics': {'accuracy': 0.74},
                   'iteration': 4,
                   'test_results': [True, True, True]},
                  {'code': 'def func_5(): pass',
                   'improvement_metrics': {'accuracy': 0.75},
                   'iteration': 5,
                   'test_results': [True]},
                  {'code': 'def func_6(): pass',
                   'improvement_metrics': {'accuracy': 0.76},
                   'iteration': 6,
                   'test_results': [True, True, True]},
                  {'code': 'def func_7(): pass',
                   'improvement_metrics': {'accuracy': 0.77},
                   'iteration': 7,
                   'test_results': [True]},
                  {'code': 'def func_8(): pass',
                   'improvement_metrics': {'accuracy': 0.7799999999999999},
                   'iteration': 8,
                   'test_results': [True, True, True]},
                  {'code': 'def func_9(): pass',
                   'improvement_metrics': {'accuracy': 0.7899999999999999},
                   'iteration': 9,
                   'test_results': [True]},
                  {'code': 'def func_10(): pass',
                   'improvement_metrics': {'accuracy': 0.7999999999999999},
                   'iteration': 10,
                   'test_results': [True, True, True]},
                  {'code': 'def func_11(): pass',
                   'improvement_metrics': {'accuracy': 0.8099999999999999},
                   'iteration': 11,
                   'test_results': [True]},
                  {'code': 'def func_12(): pass',
                   'improvement_metrics': {'accuracy': 0.82},
                   'iteration': 12,
                   'test_results': [True, True, True]},
                  {'code': 'def func_13(): pass',
                   'improvement_metrics': {'accuracy': 0.83},
                   'iteration': 13,
                   'test_results': [True]},
                  {'code': 'def func_14(): pass',
                   'improvement_metrics': {'accuracy': 0.84},
                   'iteration': 14,
                   'test_results': [True, True, True]},
                  {'code': 'def func_15(): pass',
                   'improvement_metrics': {'accuracy': 0.85},
                   'iteration': 15,
                   'test_results': [True]},
                  {'code': 'def func_16(): pass',
                   'improvement_metrics': {'accuracy': 0.86},
                   'iteration': 16,
                   'test_results': [True, True, True]},
                  {'code': 'def func_17(): pass',
                   'improvement_metrics': {'accuracy': 0.87},
                   'iteration': 17,
                   'test_results': [True]},
                  {'code': 'def func_18(): pass',
                   'improvement_metrics': {'accuracy': 0.8799999999999999},
                   'iteration': 18,
                   'test_results': [True, True, True]},
                  {'code': 'def func_19(): pass',
                   'improvement_metrics': {'accuracy': 0.8899999999999999},
                   'iteration': 19,
                   'test_results': [True]}]}
        archive_path = PosixPath('/tmp/tmpnedlppbr/archive-filtered.json')
        f          = <_io.TextIOWrapper name='/tmp/tmpnedlppbr/archive-filtered.json' mode='w' encoding='UTF-8'>
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a3f0710>
        tmpdir     = '/tmp/tmpnedlppbr'
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a3f0710>,)
        context    = None
        func       = <function FineTuningPipeline.prepare_se_darwin_dataset at 0x78d40a64b240>
        kwargs     = {'archive_path': '/tmp/tmpnedlppbr/archive-filtered.json',
 'max_trajectories': 15,
 'min_test_pass_rate': 0.9,
 'output_gcs_uri': 'gs://test-bucket/filtered'}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.prepare_se_darwin_dataset'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:439: in prepare_se_darwin_dataset
    raise ValueError(f"No valid training examples found in {archive_path}")
E   ValueError: No valid training examples found in /tmp/tmpnedlppbr/archive-filtered.json
        archive_dir = PosixPath('/tmp/tmpnedlppbr/archive-filtered.json')
        archive_path = '/tmp/tmpnedlppbr/archive-filtered.json'
        max_trajectories = 15
        min_test_pass_rate = 0.9
        output_gcs_uri = 'gs://test-bucket/filtered'
        quality_threshold = 0.8
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a3f0710>
        training_examples = []
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Preparing SE-Darwin dataset from /tmp/tmpnedlppbr/archive-filtered.json → gs://test-bucket/filtered
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:392 Preparing SE-Darwin dataset from /tmp/tmpnedlppbr/archive-filtered.json → gs://test-bucket/filtered
__________________ test_prepare_halo_routing_dataset_success ___________________
tests/vertex/test_fine_tuning_pipeline.py:145: in test_prepare_halo_routing_dataset_success
    dataset = await fine_tuning_pipeline.prepare_halo_routing_dataset(
        decision   = {'selected_agent': 'agent_4', 'success': False, 'task': 'Task 19'}
        decisions_path = PosixPath('/tmp/tmpqlbvh8ac/routing-decisions.jsonl')
        f          = <_io.TextIOWrapper name='/tmp/tmpqlbvh8ac/routing-decisions.jsonl' mode='w' encoding='UTF-8'>
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2998e0>
        i          = 19
        tmpdir     = '/tmp/tmpqlbvh8ac'
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2998e0>,)
        context    = None
        func       = <function FineTuningPipeline.prepare_halo_routing_dataset at 0x78d40a64b380>
        kwargs     = {'min_success_rate': 0.3,
 'output_gcs_uri': 'gs://test-bucket/halo-routing',
 'routing_decisions_path': '/tmp/tmpqlbvh8ac/routing-decisions.jsonl'}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.prepare_halo_routing_dataset'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:549: in prepare_halo_routing_dataset
    raise ValueError(f"No valid routing decisions found in {routing_decisions_path}")
E   ValueError: No valid routing decisions found in /tmp/tmpqlbvh8ac/routing-decisions.jsonl
        decision   = {'selected_agent': 'agent_4', 'success': False, 'task': 'Task 19'}
        decisions_file = PosixPath('/tmp/tmpqlbvh8ac/routing-decisions.jsonl')
        f          = <_io.TextIOWrapper name='/tmp/tmpqlbvh8ac/routing-decisions.jsonl' mode='r' encoding='UTF-8'>
        line       = '{"task": "Task 19", "selected_agent": "agent_4", "success": false}\n'
        min_success_rate = 0.3
        output_gcs_uri = 'gs://test-bucket/halo-routing'
        routing_decisions_path = '/tmp/tmpqlbvh8ac/routing-decisions.jsonl'
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2998e0>
        success_rate = 0.0
        training_examples = []
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Preparing HALO routing dataset from /tmp/tmpqlbvh8ac/routing-decisions.jsonl → gs://test-bucket/halo-routing
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:506 Preparing HALO routing dataset from /tmp/tmpqlbvh8ac/routing-decisions.jsonl → gs://test-bucket/halo-routing
_________________ test_prepare_halo_routing_dataset_validation _________________
tests/vertex/test_fine_tuning_pipeline.py:168: in test_prepare_halo_routing_dataset_validation
    dataset = await fine_tuning_pipeline.prepare_halo_routing_dataset(
        decision   = {'selected_agent': 'agent_1', 'success': False, 'task': 'Query 29'}
        decisions_path = PosixPath('/tmp/tmphim_kmrn/routing-valid.jsonl')
        f          = <_io.TextIOWrapper name='/tmp/tmphim_kmrn/routing-valid.jsonl' mode='w' encoding='UTF-8'>
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2e1910>
        i          = 29
        tmpdir     = '/tmp/tmphim_kmrn'
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2e1910>,)
        context    = None
        func       = <function FineTuningPipeline.prepare_halo_routing_dataset at 0x78d40a64b380>
        kwargs     = {'min_success_rate': 0.8,
 'output_gcs_uri': 'gs://test-bucket/halo-validated',
 'routing_decisions_path': '/tmp/tmphim_kmrn/routing-valid.jsonl'}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.prepare_halo_routing_dataset'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:549: in prepare_halo_routing_dataset
    raise ValueError(f"No valid routing decisions found in {routing_decisions_path}")
E   ValueError: No valid routing decisions found in /tmp/tmphim_kmrn/routing-valid.jsonl
        decision   = {'selected_agent': 'agent_1', 'success': False, 'task': 'Query 29'}
        decisions_file = PosixPath('/tmp/tmphim_kmrn/routing-valid.jsonl')
        f          = <_io.TextIOWrapper name='/tmp/tmphim_kmrn/routing-valid.jsonl' mode='r' encoding='UTF-8'>
        line       = '{"task": "Query 29", "selected_agent": "agent_1", "success": false}\n'
        min_success_rate = 0.8
        output_gcs_uri = 'gs://test-bucket/halo-validated'
        routing_decisions_path = '/tmp/tmphim_kmrn/routing-valid.jsonl'
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2e1910>
        success_rate = 0.0
        training_examples = []
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Preparing HALO routing dataset from /tmp/tmphim_kmrn/routing-valid.jsonl → gs://test-bucket/halo-validated
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:506 Preparing HALO routing dataset from /tmp/tmphim_kmrn/routing-valid.jsonl → gs://test-bucket/halo-validated
______________________ test_submit_tuning_job_supervised _______________________
tests/vertex/test_fine_tuning_pipeline.py:180: in test_submit_tuning_job_supervised
    job = await fine_tuning_pipeline.submit_tuning_job(
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a339a30>
        sample_tuning_config = TuningJobConfig(name='test-tuning-job',
                job_name='test-tuning-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                        validation_uri='gs://test-bucket/validation-data.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=20,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                     batch_size=32,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='test-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=['project:test', 'model:gemini'])
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a339a30>,)
        context    = None
        func       = <function FineTuningPipeline.submit_tuning_job at 0x78d40a64b4c0>
        kwargs     = {'config': TuningJobConfig(name='test-tuning-job',
                           job_name='test-tuning-job-full',
                           base_model='gemini-pro',
                           tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                           dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                                   validation_uri='gs://test-bucket/validation-data.jsonl',
                                                   test_uri=None,
                                                   num_train_samples=100,
                                                   num_val_samples=20,
                                                   format='jsonl'),
                           hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                                batch_size=32,
                                                                num_epochs=3,
                                                                warmup_steps=100,
                                                                weight_decay=0.01,
                                                                max_seq_length=2048,
                                                                gradient_accumulation_steps=1,
                                                                scheduler='linear',
                                                                optimizer='adamw',
                                                                lora_r=8,
                                                                lora_alpha=16,
                                                                lora_dropout=0.05),
                           rlhf_config=None,
                           distillation_config=None,
                           output_model_name='test-tuned-model',
                           output_model_version='1.0.0',
                           machine_type='n1-highmem-8',
                           accelerator_type='NVIDIA_TESLA_T4',
                           accelerator_count=1,
                           max_run_time_hours=24,
                           enable_checkpointing=True,
                           checkpoint_frequency=500,
                           enable_early_stopping=True,
                           early_stopping_patience=3,
                           tags=['project:test', 'model:gemini']),
 'wait_for_completion': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.submit_tuning_job'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:632: in submit_tuning_job
    vertex_job = await self._submit_supervised_job(config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = TuningJobConfig(name='test-tuning-job',
                job_name='test-tuning-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                        validation_uri='gs://test-bucket/validation-data.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=20,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                     batch_size=32,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='test-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=['project:test', 'model:gemini'])
        job_id     = 'test-tuning-job-full'
        progress_callback = None
        result     = TuningJobResult(job_id='test-tuning-job-full',
                job_name='test-tuning-job-full',
                status=<TuningJobStatus.FAILED: 'failed'>,
                tuned_model_uri=None,
                metrics={},
                start_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 666741),
                end_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 666793),
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message='staging_bucket should be passed to '
                              'CustomJob.from_local_script or should be set '
                              'using '
                              "aiplatform.init(staging_bucket='gs://my-bucket')")
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a339a30>
        start_time = 1762268312.6666539
        wait_for_completion = False
infrastructure/vertex_ai/fine_tuning_pipeline.py:693: in _submit_supervised_job
    job = CustomJob.from_local_script(
        config     = TuningJobConfig(name='test-tuning-job',
                job_name='test-tuning-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                        validation_uri='gs://test-bucket/validation-data.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=20,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                     batch_size=32,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='test-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=['project:test', 'model:gemini'])
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a339a30>
        training_args = {'base_model': 'gemini-pro',
 'batch_size': 32,
 'checkpoint_frequency': 500,
 'early_stopping': True,
 'early_stopping_patience': 3,
 'learning_rate': 0.001,
 'max_seq_length': 2048,
 'num_epochs': 3,
 'output_dir': 'gs://test-project-tuning-outputs/test-tuning-job-full',
 'train_data': 'gs://test-bucket/training-data.jsonl',
 'validation_data': 'gs://test-bucket/validation-data.jsonl'}
venv/lib/python3.12/site-packages/google/cloud/aiplatform/jobs.py:2085: in from_local_script
    raise RuntimeError(
E   RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
        accelerator_count = 1
        accelerator_type = 'NVIDIA_TESLA_T4'
        args       = ('{"base_model": "gemini-pro", "train_data": '
 '"gs://test-bucket/training-data.jsonl", "validation_data": '
 '"gs://test-bucket/validation-data.jsonl", "learning_rate": 0.001, '
 '"batch_size": 32, "num_epochs": 3, "max_seq_length": 2048, "output_dir": '
 '"gs://test-project-tuning-outputs/test-tuning-job-full", '
 '"checkpoint_frequency": 500, "early_stopping": true, '
 '"early_stopping_patience": 3}')
        base_output_dir = None
        boot_disk_size_gb = 100
        boot_disk_type = 'pd-ssd'
        cls        = <class 'google.cloud.aiplatform.jobs.CustomJob'>
        container_uri = 'gcr.io/test-project/training-container:latest'
        credentials = None
        display_name = 'test-tuning-job-full'
        enable_autolog = False
        encryption_spec_key_name = None
        environment_variables = None
        labels     = None
        location   = 'us-central1'
        machine_type = 'n1-highmem-8'
        persistent_resource_id = None
        project    = 'test-project'
        reduction_server_container_uri = None
        reduction_server_machine_type = None
        reduction_server_replica_count = 0
        replica_count = 1
        requirements = None
        script_path = 'training_scripts/supervised_finetune.py'
        staging_bucket = None
        tpu_topology = None
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Submitting tuning job: test-tuning-job-full (type=supervised, base_model=gemini-pro)
ERROR:vertex_ai.fine_tuning:Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:614 Submitting tuning job: test-tuning-job-full (type=supervised, base_model=gemini-pro)
ERROR    vertex_ai.fine_tuning:fine_tuning_pipeline.py:668 Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
_________________________ test_submit_tuning_job_rlhf __________________________
tests/vertex/test_fine_tuning_pipeline.py:214: in test_submit_tuning_job_rlhf
    job = await fine_tuning_pipeline.submit_tuning_job(
        HyperparameterConfig = <class 'infrastructure.vertex_ai.fine_tuning_pipeline.HyperparameterConfig'>
        RLHFConfig = <class 'infrastructure.vertex_ai.fine_tuning_pipeline.RLHFConfig'>
        config     = TuningJobConfig(name='rlhf-tuning',
                job_name='rlhf-tuning-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.RLHF: 'rlhf'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/rlhf-data.jsonl',
                                        validation_uri='gs://test-bucket/rlhf-val.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.0001,
                                                     batch_size=8,
                                                     num_epochs=5,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=RLHFConfig(reward_model_uri='gs://test-bucket/reward_model_v1',
                                       ppo_epochs=4,
                                       ppo_clip_range=0.2,
                                       value_loss_coef=0.5,
                                       kl_penalty_coef=0.1,
                                       reference_model_uri=None),
                distillation_config=None,
                output_model_name='rlhf-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2e35c0>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2e35c0>,)
        context    = None
        func       = <function FineTuningPipeline.submit_tuning_job at 0x78d40a64b4c0>
        kwargs     = {'config': TuningJobConfig(name='rlhf-tuning',
                           job_name='rlhf-tuning-full',
                           base_model='gemini-pro',
                           tuning_type=<TuningType.RLHF: 'rlhf'>,
                           dataset=TrainingDataset(train_uri='gs://test-bucket/rlhf-data.jsonl',
                                                   validation_uri='gs://test-bucket/rlhf-val.jsonl',
                                                   test_uri=None,
                                                   num_train_samples=100,
                                                   num_val_samples=0,
                                                   format='jsonl'),
                           hyperparameters=HyperparameterConfig(learning_rate=0.0001,
                                                                batch_size=8,
                                                                num_epochs=5,
                                                                warmup_steps=100,
                                                                weight_decay=0.01,
                                                                max_seq_length=2048,
                                                                gradient_accumulation_steps=1,
                                                                scheduler='linear',
                                                                optimizer='adamw',
                                                                lora_r=8,
                                                                lora_alpha=16,
                                                                lora_dropout=0.05),
                           rlhf_config=RLHFConfig(reward_model_uri='gs://test-bucket/reward_model_v1',
                                                  ppo_epochs=4,
                                                  ppo_clip_range=0.2,
                                                  value_loss_coef=0.5,
                                                  kl_penalty_coef=0.1,
                                                  reference_model_uri=None),
                           distillation_config=None,
                           output_model_name='rlhf-tuned-model',
                           output_model_version='1.0.0',
                           machine_type='n1-highmem-8',
                           accelerator_type='NVIDIA_TESLA_T4',
                           accelerator_count=1,
                           max_run_time_hours=24,
                           enable_checkpointing=True,
                           checkpoint_frequency=500,
                           enable_early_stopping=True,
                           early_stopping_patience=3,
                           tags=[]),
 'wait_for_completion': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.submit_tuning_job'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:634: in submit_tuning_job
    vertex_job = await self._submit_rlhf_job(config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = TuningJobConfig(name='rlhf-tuning',
                job_name='rlhf-tuning-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.RLHF: 'rlhf'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/rlhf-data.jsonl',
                                        validation_uri='gs://test-bucket/rlhf-val.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.0001,
                                                     batch_size=8,
                                                     num_epochs=5,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=RLHFConfig(reward_model_uri='gs://test-bucket/reward_model_v1',
                                       ppo_epochs=4,
                                       ppo_clip_range=0.2,
                                       value_loss_coef=0.5,
                                       kl_penalty_coef=0.1,
                                       reference_model_uri=None),
                distillation_config=None,
                output_model_name='rlhf-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        job_id     = 'rlhf-tuning-full'
        progress_callback = None
        result     = TuningJobResult(job_id='rlhf-tuning-full',
                job_name='rlhf-tuning-full',
                status=<TuningJobStatus.FAILED: 'failed'>,
                tuned_model_uri=None,
                metrics={},
                start_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 719172),
                end_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 719224),
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message='staging_bucket should be passed to '
                              'CustomJob.from_local_script or should be set '
                              'using '
                              "aiplatform.init(staging_bucket='gs://my-bucket')")
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2e35c0>
        start_time = 1762268312.7190912
        wait_for_completion = False
infrastructure/vertex_ai/fine_tuning_pipeline.py:729: in _submit_rlhf_job
    job = CustomJob.from_local_script(
        config     = TuningJobConfig(name='rlhf-tuning',
                job_name='rlhf-tuning-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.RLHF: 'rlhf'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/rlhf-data.jsonl',
                                        validation_uri='gs://test-bucket/rlhf-val.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.0001,
                                                     batch_size=8,
                                                     num_epochs=5,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=RLHFConfig(reward_model_uri='gs://test-bucket/reward_model_v1',
                                       ppo_epochs=4,
                                       ppo_clip_range=0.2,
                                       value_loss_coef=0.5,
                                       kl_penalty_coef=0.1,
                                       reference_model_uri=None),
                distillation_config=None,
                output_model_name='rlhf-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2e35c0>
        training_args = {'base_model': 'gemini-pro',
 'kl_penalty': 0.1,
 'output_dir': 'gs://test-project-tuning-outputs/rlhf-tuning-full',
 'ppo_clip_range': 0.2,
 'ppo_epochs': 4,
 'reference_model': None,
 'reward_model': 'gs://test-bucket/reward_model_v1',
 'train_data': 'gs://test-bucket/rlhf-data.jsonl'}
venv/lib/python3.12/site-packages/google/cloud/aiplatform/jobs.py:2085: in from_local_script
    raise RuntimeError(
E   RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
        accelerator_count = 1
        accelerator_type = 'NVIDIA_TESLA_T4'
        args       = ('{"base_model": "gemini-pro", "reward_model": '
 '"gs://test-bucket/reward_model_v1", "reference_model": null, "train_data": '
 '"gs://test-bucket/rlhf-data.jsonl", "ppo_epochs": 4, "ppo_clip_range": 0.2, '
 '"kl_penalty": 0.1, "output_dir": '
 '"gs://test-project-tuning-outputs/rlhf-tuning-full"}')
        base_output_dir = None
        boot_disk_size_gb = 100
        boot_disk_type = 'pd-ssd'
        cls        = <class 'google.cloud.aiplatform.jobs.CustomJob'>
        container_uri = 'gcr.io/test-project/rlhf-container:latest'
        credentials = None
        display_name = 'rlhf-tuning-full'
        enable_autolog = False
        encryption_spec_key_name = None
        environment_variables = None
        labels     = None
        location   = 'us-central1'
        machine_type = 'n1-highmem-8'
        persistent_resource_id = None
        project    = 'test-project'
        reduction_server_container_uri = None
        reduction_server_machine_type = None
        reduction_server_replica_count = 0
        replica_count = 1
        requirements = None
        script_path = 'training_scripts/rlhf_finetune.py'
        staging_bucket = None
        tpu_topology = None
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Submitting tuning job: rlhf-tuning-full (type=rlhf, base_model=gemini-pro)
ERROR:vertex_ai.fine_tuning:Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:614 Submitting tuning job: rlhf-tuning-full (type=rlhf, base_model=gemini-pro)
ERROR    vertex_ai.fine_tuning:fine_tuning_pipeline.py:668 Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
_____________________ test_submit_tuning_job_distillation ______________________
tests/vertex/test_fine_tuning_pipeline.py:246: in test_submit_tuning_job_distillation
    job = await fine_tuning_pipeline.submit_tuning_job(
        DistillationConfig = <class 'infrastructure.vertex_ai.fine_tuning_pipeline.DistillationConfig'>
        HyperparameterConfig = <class 'infrastructure.vertex_ai.fine_tuning_pipeline.HyperparameterConfig'>
        config     = TuningJobConfig(name='distillation-job',
                job_name='distillation-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.DISTILLATION: 'distillation'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/distil-data.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                     batch_size=8,
                                                     num_epochs=2,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=DistillationConfig(teacher_model_uri='gs://test-bucket/gemini-2.0-pro',
                                                       temperature=4.0,
                                                       alpha=0.5,
                                                       student_model_size='small'),
                output_model_name='distillation-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a3517f0>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a3517f0>,)
        context    = None
        func       = <function FineTuningPipeline.submit_tuning_job at 0x78d40a64b4c0>
        kwargs     = {'config': TuningJobConfig(name='distillation-job',
                           job_name='distillation-job-full',
                           base_model='gemini-pro',
                           tuning_type=<TuningType.DISTILLATION: 'distillation'>,
                           dataset=TrainingDataset(train_uri='gs://test-bucket/distil-data.jsonl',
                                                   validation_uri=None,
                                                   test_uri=None,
                                                   num_train_samples=100,
                                                   num_val_samples=0,
                                                   format='jsonl'),
                           hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                                batch_size=8,
                                                                num_epochs=2,
                                                                warmup_steps=100,
                                                                weight_decay=0.01,
                                                                max_seq_length=2048,
                                                                gradient_accumulation_steps=1,
                                                                scheduler='linear',
                                                                optimizer='adamw',
                                                                lora_r=8,
                                                                lora_alpha=16,
                                                                lora_dropout=0.05),
                           rlhf_config=None,
                           distillation_config=DistillationConfig(teacher_model_uri='gs://test-bucket/gemini-2.0-pro',
                                                                  temperature=4.0,
                                                                  alpha=0.5,
                                                                  student_model_size='small'),
                           output_model_name='distillation-tuned-model',
                           output_model_version='1.0.0',
                           machine_type='n1-highmem-8',
                           accelerator_type='NVIDIA_TESLA_T4',
                           accelerator_count=1,
                           max_run_time_hours=24,
                           enable_checkpointing=True,
                           checkpoint_frequency=500,
                           enable_early_stopping=True,
                           early_stopping_patience=3,
                           tags=[]),
 'wait_for_completion': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.submit_tuning_job'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:636: in submit_tuning_job
    vertex_job = await self._submit_distillation_job(config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = TuningJobConfig(name='distillation-job',
                job_name='distillation-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.DISTILLATION: 'distillation'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/distil-data.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                     batch_size=8,
                                                     num_epochs=2,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=DistillationConfig(teacher_model_uri='gs://test-bucket/gemini-2.0-pro',
                                                       temperature=4.0,
                                                       alpha=0.5,
                                                       student_model_size='small'),
                output_model_name='distillation-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        job_id     = 'distillation-job-full'
        progress_callback = None
        result     = TuningJobResult(job_id='distillation-job-full',
                job_name='distillation-job-full',
                status=<TuningJobStatus.FAILED: 'failed'>,
                tuned_model_uri=None,
                metrics={},
                start_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 767692),
                end_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 767746),
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message='staging_bucket should be passed to '
                              'CustomJob.from_local_script or should be set '
                              'using '
                              "aiplatform.init(staging_bucket='gs://my-bucket')")
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a3517f0>
        start_time = 1762268312.7675982
        wait_for_completion = False
infrastructure/vertex_ai/fine_tuning_pipeline.py:760: in _submit_distillation_job
    job = CustomJob.from_local_script(
        config     = TuningJobConfig(name='distillation-job',
                job_name='distillation-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.DISTILLATION: 'distillation'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/distil-data.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                     batch_size=8,
                                                     num_epochs=2,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=DistillationConfig(teacher_model_uri='gs://test-bucket/gemini-2.0-pro',
                                                       temperature=4.0,
                                                       alpha=0.5,
                                                       student_model_size='small'),
                output_model_name='distillation-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a3517f0>
        training_args = {'alpha': 0.5,
 'output_dir': 'gs://test-project-tuning-outputs/distillation-job-full',
 'student_model': 'gemini-pro',
 'teacher_model': 'gs://test-bucket/gemini-2.0-pro',
 'temperature': 4.0,
 'train_data': 'gs://test-bucket/distil-data.jsonl'}
venv/lib/python3.12/site-packages/google/cloud/aiplatform/jobs.py:2085: in from_local_script
    raise RuntimeError(
E   RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
        accelerator_count = 1
        accelerator_type = 'NVIDIA_TESLA_T4'
        args       = ('{"teacher_model": "gs://test-bucket/gemini-2.0-pro", "student_model": '
 '"gemini-pro", "train_data": "gs://test-bucket/distil-data.jsonl", '
 '"temperature": 4.0, "alpha": 0.5, "output_dir": '
 '"gs://test-project-tuning-outputs/distillation-job-full"}')
        base_output_dir = None
        boot_disk_size_gb = 100
        boot_disk_type = 'pd-ssd'
        cls        = <class 'google.cloud.aiplatform.jobs.CustomJob'>
        container_uri = 'gcr.io/test-project/distillation-container:latest'
        credentials = None
        display_name = 'distillation-job-full'
        enable_autolog = False
        encryption_spec_key_name = None
        environment_variables = None
        labels     = None
        location   = 'us-central1'
        machine_type = 'n1-highmem-8'
        persistent_resource_id = None
        project    = 'test-project'
        reduction_server_container_uri = None
        reduction_server_machine_type = None
        reduction_server_replica_count = 0
        replica_count = 1
        requirements = None
        script_path = 'training_scripts/distillation.py'
        staging_bucket = None
        tpu_topology = None
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Submitting tuning job: distillation-job-full (type=distillation, base_model=gemini-pro)
ERROR:vertex_ai.fine_tuning:Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:614 Submitting tuning job: distillation-job-full (type=distillation, base_model=gemini-pro)
ERROR    vertex_ai.fine_tuning:fine_tuning_pipeline.py:668 Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
__________________ test_submit_tuning_job_parameter_efficient __________________
tests/vertex/test_fine_tuning_pipeline.py:276: in test_submit_tuning_job_parameter_efficient
    job = await fine_tuning_pipeline.submit_tuning_job(
        HyperparameterConfig = <class 'infrastructure.vertex_ai.fine_tuning_pipeline.HyperparameterConfig'>
        config     = TuningJobConfig(name='lora-tuning',
                job_name='lora-tuning-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.PARAMETER_EFFICIENT: 'peft'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/peft-data.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                     batch_size=8,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='lora-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29a2d0>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29a2d0>,)
        context    = None
        func       = <function FineTuningPipeline.submit_tuning_job at 0x78d40a64b4c0>
        kwargs     = {'config': TuningJobConfig(name='lora-tuning',
                           job_name='lora-tuning-full',
                           base_model='gemini-pro',
                           tuning_type=<TuningType.PARAMETER_EFFICIENT: 'peft'>,
                           dataset=TrainingDataset(train_uri='gs://test-bucket/peft-data.jsonl',
                                                   validation_uri=None,
                                                   test_uri=None,
                                                   num_train_samples=100,
                                                   num_val_samples=0,
                                                   format='jsonl'),
                           hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                                batch_size=8,
                                                                num_epochs=3,
                                                                warmup_steps=100,
                                                                weight_decay=0.01,
                                                                max_seq_length=2048,
                                                                gradient_accumulation_steps=1,
                                                                scheduler='linear',
                                                                optimizer='adamw',
                                                                lora_r=8,
                                                                lora_alpha=16,
                                                                lora_dropout=0.05),
                           rlhf_config=None,
                           distillation_config=None,
                           output_model_name='lora-tuned-model',
                           output_model_version='1.0.0',
                           machine_type='n1-highmem-8',
                           accelerator_type='NVIDIA_TESLA_T4',
                           accelerator_count=1,
                           max_run_time_hours=24,
                           enable_checkpointing=True,
                           checkpoint_frequency=500,
                           enable_early_stopping=True,
                           early_stopping_patience=3,
                           tags=[]),
 'wait_for_completion': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.submit_tuning_job'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:638: in submit_tuning_job
    vertex_job = await self._submit_peft_job(config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = TuningJobConfig(name='lora-tuning',
                job_name='lora-tuning-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.PARAMETER_EFFICIENT: 'peft'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/peft-data.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                     batch_size=8,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='lora-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        job_id     = 'lora-tuning-full'
        progress_callback = None
        result     = TuningJobResult(job_id='lora-tuning-full',
                job_name='lora-tuning-full',
                status=<TuningJobStatus.FAILED: 'failed'>,
                tuned_model_uri=None,
                metrics={},
                start_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 823235),
                end_time=datetime.datetime(2025, 11, 4, 14, 58, 32, 823309),
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message='staging_bucket should be passed to '
                              'CustomJob.from_local_script or should be set '
                              'using '
                              "aiplatform.init(staging_bucket='gs://my-bucket')")
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29a2d0>
        start_time = 1762268312.8231006
        wait_for_completion = False
infrastructure/vertex_ai/fine_tuning_pipeline.py:791: in _submit_peft_job
    job = CustomJob.from_local_script(
        config     = TuningJobConfig(name='lora-tuning',
                job_name='lora-tuning-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.PARAMETER_EFFICIENT: 'peft'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/peft-data.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=1e-05,
                                                     batch_size=8,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='lora-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29a2d0>
        training_args = {'base_model': 'gemini-pro',
 'batch_size': 8,
 'learning_rate': 1e-05,
 'lora_alpha': 16,
 'lora_dropout': 0.05,
 'lora_r': 8,
 'num_epochs': 3,
 'output_dir': 'gs://test-project-tuning-outputs/lora-tuning-full',
 'train_data': 'gs://test-bucket/peft-data.jsonl'}
venv/lib/python3.12/site-packages/google/cloud/aiplatform/jobs.py:2085: in from_local_script
    raise RuntimeError(
E   RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
        accelerator_count = 1
        accelerator_type = 'NVIDIA_TESLA_T4'
        args       = ('{"base_model": "gemini-pro", "train_data": '
 '"gs://test-bucket/peft-data.jsonl", "lora_r": 8, "lora_alpha": 16, '
 '"lora_dropout": 0.05, "learning_rate": 1e-05, "batch_size": 8, "num_epochs": '
 '3, "output_dir": "gs://test-project-tuning-outputs/lora-tuning-full"}')
        base_output_dir = None
        boot_disk_size_gb = 100
        boot_disk_type = 'pd-ssd'
        cls        = <class 'google.cloud.aiplatform.jobs.CustomJob'>
        container_uri = 'gcr.io/test-project/peft-container:latest'
        credentials = None
        display_name = 'lora-tuning-full'
        enable_autolog = False
        encryption_spec_key_name = None
        environment_variables = None
        labels     = None
        location   = 'us-central1'
        machine_type = 'n1-highmem-8'
        persistent_resource_id = None
        project    = 'test-project'
        reduction_server_container_uri = None
        reduction_server_machine_type = None
        reduction_server_replica_count = 0
        replica_count = 1
        requirements = None
        script_path = 'training_scripts/peft_finetune.py'
        staging_bucket = None
        tpu_topology = None
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Submitting tuning job: lora-tuning-full (type=peft, base_model=gemini-pro)
ERROR:vertex_ai.fine_tuning:Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:614 Submitting tuning job: lora-tuning-full (type=peft, base_model=gemini-pro)
ERROR    vertex_ai.fine_tuning:fine_tuning_pipeline.py:668 Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
______________________ test_register_tuned_model_success _______________________
venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:75: in error_remapped_callable
    return callable_(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}
,)
        callable_  = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d40a32ab70>
        kwargs     = {'metadata': [('x-goog-request-params',
               'parent=projects/test-project/locations/us-central1'),
              ('x-goog-api-client',
               'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
               'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
               'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]}
venv/lib/python3.12/site-packages/grpc/_interceptor.py:277: in __call__
    response, ignored_call = self._with_call(
        compression = None
        credentials = None
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}

        self       = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d40a32ab70>
        timeout    = None
        wait_for_ready = None
venv/lib/python3.12/site-packages/grpc/_interceptor.py:332: in _with_call
    return call.result(), call
           ^^^^^^^^^^^^^
        call       = <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.PERMISSION_DENIED
	details = "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4004:c1f::5f%5D:443 {grpc_status:7, grpc_message:"Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."}"
>
        client_call_details = _ClientCallDetails(method='/google.cloud.aiplatform.v1.ModelService/UploadModel', timeout=None, metadata=[('x-goog-request-params', 'parent=projects/test-project/locations/us-central1'), ('x-goog-api-client', 'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')], credentials=None, wait_for_ready=None, compression=None)
        compression = None
        continuation = <function _UnaryUnaryMultiCallable._with_call.<locals>.continuation at 0x78d409fa9760>
        credentials = None
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}

        self       = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d40a32ab70>
        timeout    = None
        wait_for_ready = None
venv/lib/python3.12/site-packages/grpc/_channel.py:440: in result
    raise self
        self       = <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.PERMISSION_DENIED
	details = "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4004:c1f::5f%5D:443 {grpc_status:7, grpc_message:"Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."}"
>
        timeout    = None
venv/lib/python3.12/site-packages/grpc/_interceptor.py:315: in continuation
    response, call = self._thunk(new_method).with_call(
        client_call_details = _ClientCallDetails(method='/google.cloud.aiplatform.v1.ModelService/UploadModel', timeout=None, metadata=[('x-goog-request-params', 'parent=projects/test-project/locations/us-central1'), ('x-goog-api-client', 'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')], credentials=None, wait_for_ready=None, compression=None)
        new_compression = None
        new_credentials = None
        new_details = _ClientCallDetails(method='/google.cloud.aiplatform.v1.ModelService/UploadModel', timeout=None, metadata=[('x-goog-request-params', 'parent=projects/test-project/locations/us-central1'), ('x-goog-api-client', 'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')], credentials=None, wait_for_ready=None, compression=None)
        new_metadata = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        new_method = '/google.cloud.aiplatform.v1.ModelService/UploadModel'
        new_timeout = None
        new_wait_for_ready = None
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}

        self       = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d40a32ab70>
venv/lib/python3.12/site-packages/grpc/_channel.py:1195: in with_call
    return _end_unary_response_blocking(state, call, True, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        call       = <grpc._cython.cygrpc.SegregatedCall object at 0x78d40a09e6c0>
        compression = None
        credentials = None
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}

        self       = <grpc._channel._UnaryUnaryMultiCallable object at 0x78d409ff0f30>
        state      = <grpc._channel._RPCState object at 0x78d40a2eee70>
        timeout    = None
        wait_for_ready = None
venv/lib/python3.12/site-packages/grpc/_channel.py:1009: in _end_unary_response_blocking
    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:
E   	status = StatusCode.PERMISSION_DENIED
E   	details = "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
E   	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4004:c1f::5f%5D:443 {grpc_status:7, grpc_message:"Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."}"
E   >
        call       = <grpc._cython.cygrpc.SegregatedCall object at 0x78d40a09e6c0>
        deadline   = None
        state      = <grpc._channel._RPCState object at 0x78d40a2eee70>
        with_call  = True

The above exception was the direct cause of the following exception:
tests/vertex/test_fine_tuning_pipeline.py:296: in test_register_tuned_model_success
    metadata = await fine_tuning_pipeline.register_tuned_model(
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29b950>
        result     = TuningJobResult(job_id='test-job-123',
                job_name='test-job-123-full',
                status=<TuningJobStatus.SUCCEEDED: 'succeeded'>,
                tuned_model_uri='gs://test-bucket/tuned-model',
                metrics={'eval_accuracy': 0.92, 'eval_loss': 0.25},
                start_time=None,
                end_time=None,
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message=None)
        sample_tuning_config = TuningJobConfig(name='test-tuning-job',
                job_name='test-tuning-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                        validation_uri='gs://test-bucket/validation-data.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=20,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                     batch_size=32,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='test-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=['project:test', 'model:gemini'])
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29b950>,)
        context    = None
        func       = <function FineTuningPipeline.register_tuned_model at 0x78d40a64b920>
        kwargs     = {'config': TuningJobConfig(name='test-tuning-job',
                           job_name='test-tuning-job-full',
                           base_model='gemini-pro',
                           tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                           dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                                   validation_uri='gs://test-bucket/validation-data.jsonl',
                                                   test_uri=None,
                                                   num_train_samples=100,
                                                   num_val_samples=20,
                                                   format='jsonl'),
                           hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                                batch_size=32,
                                                                num_epochs=3,
                                                                warmup_steps=100,
                                                                weight_decay=0.01,
                                                                max_seq_length=2048,
                                                                gradient_accumulation_steps=1,
                                                                scheduler='linear',
                                                                optimizer='adamw',
                                                                lora_r=8,
                                                                lora_alpha=16,
                                                                lora_dropout=0.05),
                           rlhf_config=None,
                           distillation_config=None,
                           output_model_name='test-tuned-model',
                           output_model_version='1.0.0',
                           machine_type='n1-highmem-8',
                           accelerator_type='NVIDIA_TESLA_T4',
                           accelerator_count=1,
                           max_run_time_hours=24,
                           enable_checkpointing=True,
                           checkpoint_frequency=500,
                           enable_early_stopping=True,
                           early_stopping_patience=3,
                           tags=['project:test', 'model:gemini']),
 'result': TuningJobResult(job_id='test-job-123',
                           job_name='test-job-123-full',
                           status=<TuningJobStatus.SUCCEEDED: 'succeeded'>,
                           tuned_model_uri='gs://test-bucket/tuned-model',
                           metrics={'eval_accuracy': 0.92, 'eval_loss': 0.25},
                           start_time=None,
                           end_time=None,
                           duration_seconds=0.0,
                           vertex_ai_job_id=None,
                           error_message=None)}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.register_tuned_model'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:894: in register_tuned_model
    model = await self.model_registry.upload_model(metadata)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = TuningJobConfig(name='test-tuning-job',
                job_name='test-tuning-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                        validation_uri='gs://test-bucket/validation-data.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=20,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                     batch_size=32,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='test-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=['project:test', 'model:gemini'])
        metadata   = ModelMetadata(name='test-tuned-model',
              display_name='test-tuned-model-v1.0.0',
              version='1.0.0',
              description='Fine-tuned gemini-pro using supervised',
              source=<ModelSource.CUSTOM_TRAINING: 'custom'>,
              artifact_uri='gs://test-bucket/tuned-model',
              serving_container_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
              deployment_stage=<DeploymentStage.DEVELOPMENT: 'development'>,
              base_model='gemini-pro',
              performance_metrics={'eval_accuracy': 0.92, 'eval_loss': 0.25},
              cost_metrics={},
              tags=['project:test', 'model:gemini', 'supervised', 'fine-tuned'],
              created_at=datetime.datetime(2025, 11, 4, 14, 58, 32, 874345),
              updated_at=datetime.datetime(2025, 11, 4, 14, 58, 32, 874351),
              created_by='genesis',
              parent_version=None,
              vertex_ai_resource_name=None,
              custom_metadata={})
        result     = TuningJobResult(job_id='test-job-123',
                job_name='test-job-123-full',
                status=<TuningJobStatus.SUCCEEDED: 'succeeded'>,
                tuned_model_uri='gs://test-bucket/tuned-model',
                metrics={'eval_accuracy': 0.92, 'eval_loss': 0.25},
                start_time=None,
                end_time=None,
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message=None)
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29b950>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_registry.ModelRegistry object at 0x78d40a353f20>,
 ModelMetadata(name='test-tuned-model',
               display_name='test-tuned-model-v1.0.0',
               version='1.0.0',
               description='Fine-tuned gemini-pro using supervised',
               source=<ModelSource.CUSTOM_TRAINING: 'custom'>,
               artifact_uri='gs://test-bucket/tuned-model',
               serving_container_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
               deployment_stage=<DeploymentStage.DEVELOPMENT: 'development'>,
               base_model='gemini-pro',
               performance_metrics={'eval_accuracy': 0.92, 'eval_loss': 0.25},
               cost_metrics={},
               tags=['project:test',
                     'model:gemini',
                     'supervised',
                     'fine-tuned'],
               created_at=datetime.datetime(2025, 11, 4, 14, 58, 32, 874345),
               updated_at=datetime.datetime(2025, 11, 4, 14, 58, 32, 874351),
               created_by='genesis',
               parent_version=None,
               vertex_ai_resource_name=None,
               custom_metadata={}))
        context    = None
        func       = <function ModelRegistry.upload_model at 0x78d40a648e00>
        kwargs     = {}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_registry.upload_model'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_registry.py:326: in upload_model
    model = Model.upload(
        deployment_timeout = 1800
        env_vars   = {'GENESIS_DEPLOYMENT_STAGE': 'development',
 'GENESIS_MODEL_NAME': 'test-tuned-model',
 'GENESIS_MODEL_VERSION': '1.0.0'}
        labels     = None
        metadata   = ModelMetadata(name='test-tuned-model',
              display_name='test-tuned-model-v1.0.0',
              version='1.0.0',
              description='Fine-tuned gemini-pro using supervised',
              source=<ModelSource.CUSTOM_TRAINING: 'custom'>,
              artifact_uri='gs://test-bucket/tuned-model',
              serving_container_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
              deployment_stage=<DeploymentStage.DEVELOPMENT: 'development'>,
              base_model='gemini-pro',
              performance_metrics={'eval_accuracy': 0.92, 'eval_loss': 0.25},
              cost_metrics={},
              tags=['project:test', 'model:gemini', 'supervised', 'fine-tuned'],
              created_at=datetime.datetime(2025, 11, 4, 14, 58, 32, 874345),
              updated_at=datetime.datetime(2025, 11, 4, 14, 58, 32, 874351),
              created_by='genesis',
              parent_version=None,
              vertex_ai_resource_name=None,
              custom_metadata={})
        safe_tag   = 'fine_tuned'
        self       = <infrastructure.vertex_ai.model_registry.ModelRegistry object at 0x78d40a353f20>
        serving_container_env_vars = None
        serving_container_health_route = '/health'
        serving_container_ports = [8080]
        serving_container_predict_route = '/predict'
        shared_memory_mb = 16384
        start_time = 1762268312.8743303
        sync       = True
        tag        = 'fine-tuned'
        vertex_labels = {'genesis_source': 'custom',
 'genesis_stage': 'development',
 'genesis_version': '1_0_0',
 'tag_fine_tuned': 'true',
 'tag_model:gemini': 'true',
 'tag_project:test': 'true',
 'tag_supervised': 'true'}
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:862: in wrapper
    return method(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<class 'google.cloud.aiplatform.models.Model'>,)
        bind_future_to_self = True
        bound_args = <BoundArguments (cls=<class 'google.cloud.aiplatform.models.Model'>, serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest', artifact_uri='gs://test-bucket/tuned-model', serving_container_predict_route='/predict', serving_container_health_route='/health', description='Fine-tuned gemini-pro using supervised', serving_container_environment_variables={'GENESIS_MODEL_NAME': 'test-tuned-model', 'GENESIS_MODEL_VERSION': '1.0.0', 'GENESIS_DEPLOYMENT_STAGE': 'development'}, serving_container_ports=[8080], display_name='test-tuned-model-v1.0.0', labels={'genesis_version': '1_0_0', 'genesis_source': 'custom', 'genesis_stage': 'development', 'tag_project:test': 'true', 'tag_model:gemini': 'true', 'tag_supervised': 'true', 'tag_fine_tuned': 'true'}, serving_container_deployment_timeout=1800, serving_container_shared_memory_size_mb=16384)>
        calling_object_latest_future = None
        construct_object_on_arg = None
        kwargs     = {'artifact_uri': 'gs://test-bucket/tuned-model',
 'description': 'Fine-tuned gemini-pro using supervised',
 'display_name': 'test-tuned-model-v1.0.0',
 'labels': {'genesis_source': 'custom',
            'genesis_stage': 'development',
            'genesis_version': '1_0_0',
            'tag_fine_tuned': 'true',
            'tag_model:gemini': 'true',
            'tag_project:test': 'true',
            'tag_supervised': 'true'},
 'serving_container_deployment_timeout': 1800,
 'serving_container_environment_variables': {'GENESIS_DEPLOYMENT_STAGE': 'development',
                                             'GENESIS_MODEL_NAME': 'test-tuned-model',
                                             'GENESIS_MODEL_VERSION': '1.0.0'},
 'serving_container_health_route': '/health',
 'serving_container_image_uri': 'us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
 'serving_container_ports': [8080],
 'serving_container_predict_route': '/predict',
 'serving_container_shared_memory_size_mb': 16384}
        method     = <function Model.upload at 0x78d40a813ec0>
        return_input_arg = None
        self       = None
        sync       = True
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:5708: in upload
    lro = api_client.upload_model(
        api_client = <google.cloud.aiplatform.utils.ModelClientWithOverride object at 0x78d40aa34c20>
        appended_user_agent = None
        artifact_uri = 'gs://test-bucket/tuned-model'
        base_model_source = None
        cls        = <class 'google.cloud.aiplatform.models.Model'>
        container_spec = image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
env {
  name: "GENESIS_MODEL_NAME"
  value: "test-tuned-model"
}
env {
  name: "GENESIS_MODEL_VERSION"
  value: "1.0.0"
}
env {
  name: "GENESIS_DEPLOYMENT_STAGE"
  value: "development"
}
ports {
  container_port: 8080
}
predict_route: "/predict"
health_route: "/health"
deployment_timeout {
  seconds: 1800
}
shared_memory_size_mb: 16384

        credentials = None
        deployment_timeout = seconds: 1800

        description = 'Fine-tuned gemini-pro using supervised'
        display_name = 'test-tuned-model-v1.0.0'
        encryption_spec = None
        encryption_spec_key_name = None
        env        = [name: "GENESIS_MODEL_NAME"
value: "test-tuned-model"
,
 name: "GENESIS_MODEL_VERSION"
value: "1.0.0"
,
 name: "GENESIS_DEPLOYMENT_STAGE"
value: "development"
]
        explanation_metadata = None
        explanation_parameters = None
        grpc_ports = None
        health_probe = None
        instance_schema_uri = None
        is_default_version = True
        labels     = {'genesis_source': 'custom',
 'genesis_stage': 'development',
 'genesis_version': '1_0_0',
 'tag_fine_tuned': 'true',
 'tag_model:gemini': 'true',
 'tag_project:test': 'true',
 'tag_supervised': 'true'}
        local_model = None
        location   = None
        managed_model = display_name: "test-tuned-model-v1.0.0"
description: "Fine-tuned gemini-pro using supervised"
container_spec {
  image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
  env {
    name: "GENESIS_MODEL_NAME"
    value: "test-tuned-model"
  }
  env {
    name: "GENESIS_MODEL_VERSION"
    value: "1.0.0"
  }
  env {
    name: "GENESIS_DEPLOYMENT_STAGE"
    value: "development"
  }
  ports {
    container_port: 8080
  }
  predict_route: "/predict"
  health_route: "/health"
  deployment_timeout {
    seconds: 1800
  }
  shared_memory_size_mb: 16384
}
labels {
  key: "tag_supervised"
  value: "true"
}
labels {
  key: "tag_project:test"
  value: "true"
}
labels {
  key: "tag_model:gemini"
  value: "true"
}
labels {
  key: "tag_fine_tuned"
  value: "true"
}
labels {
  key: "genesis_version"
  value: "1_0_0"
}
labels {
  key: "genesis_stage"
  value: "development"
}
labels {
  key: "genesis_source"
  value: "custom"
}
artifact_uri: "gs://test-bucket/tuned-model"
version_aliases: "default"

        model_garden_source_model_name = None
        model_garden_source_model_version_id = None
        model_id   = None
        model_predict_schemata = None
        parameters_schema_uri = None
        parent_model = None
        ports      = [container_port: 8080
]
        prediction_schema_uri = None
        project    = None
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}

        serving_container_args = None
        serving_container_command = None
        serving_container_deployment_timeout = 1800
        serving_container_environment_variables = {'GENESIS_DEPLOYMENT_STAGE': 'development',
 'GENESIS_MODEL_NAME': 'test-tuned-model',
 'GENESIS_MODEL_VERSION': '1.0.0'}
        serving_container_grpc_ports = None
        serving_container_health_probe_exec = None
        serving_container_health_probe_period_seconds = None
        serving_container_health_probe_timeout_seconds = None
        serving_container_health_route = '/health'
        serving_container_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest'
        serving_container_invoke_route_prefix = None
        serving_container_ports = [8080]
        serving_container_predict_route = '/predict'
        serving_container_shared_memory_size_mb = 16384
        serving_container_startup_probe_exec = None
        serving_container_startup_probe_period_seconds = None
        serving_container_startup_probe_timeout_seconds = None
        staging_bucket = None
        startup_probe = None
        sync       = True
        upload_request_timeout = None
        version_aliases = ['default']
        version_description = None
venv/lib/python3.12/site-packages/google/cloud/aiplatform_v1/services/model_service/client.py:1002: in upload_model
    response = rpc(
        flattened_params = [None, None]
        has_flattened_params = False
        metadata   = (('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),)
        model      = None
        parent     = None
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}

        retry      = <_MethodDefault._DEFAULT_VALUE: <object object at 0x78d41bf2d210>>
        rpc        = <google.api_core.gapic_v1.method._GapicCallable object at 0x78d40a2ec3e0>
        self       = <google.cloud.aiplatform_v1.services.model_service.client.ModelServiceClient object at 0x78d40a353ce0>
        timeout    = None
venv/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131: in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}
,)
        compression = None
        kwargs     = {'metadata': [('x-goog-request-params',
               'parent=projects/test-project/locations/us-central1'),
              ('x-goog-api-client',
               'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
               'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
               'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]}
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        retry      = None
        self       = <google.api_core.gapic_v1.method._GapicCallable object at 0x78d40a2ec3e0>
        timeout    = None
        wrapped_func = <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x78d40a2a6fc0>
venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:77: in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
E   google.api_core.exceptions.PermissionDenied: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
E   domain: "googleapis.com"
E   metadata {
E     key: "service"
E     value: "aiplatform.googleapis.com"
E   }
E   metadata {
E     key: "serviceTitle"
E     value: "Vertex AI API"
E   }
E   metadata {
E     key: "containerInfo"
E     value: "test-project"
E   }
E   metadata {
E     key: "consumer"
E     value: "projects/test-project"
E   }
E   metadata {
E     key: "activationUrl"
E     value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
E   }
E   , locale: "en-US"
E   message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
E   , links {
E     description: "Google developers console API activation"
E     url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
E   }
E   ]
        args       = (parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-model"
  version_aliases: "default"
}
,)
        callable_  = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d40a32ab70>
        kwargs     = {'metadata': [('x-goog-request-params',
               'parent=projects/test-project/locations/us-central1'),
              ('x-goog-api-client',
               'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
               'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
               'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]}
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_registry:Uploading model to Vertex AI: test-tuned-model v1.0.0 (stage=development)
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1762268312.933036  512909 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
ERROR:vertex_ai.model_registry:Model upload failed: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_registry:model_registry.py:319 Uploading model to Vertex AI: test-tuned-model v1.0.0 (stage=development)
ERROR    vertex_ai.model_registry:model_registry.py:362 Model upload failed: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
___________________ test_register_tuned_model_with_metadata ____________________
venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:75: in error_remapped_callable
    return callable_(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}
,)
        callable_  = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d409c5a660>
        kwargs     = {'metadata': [('x-goog-request-params',
               'parent=projects/test-project/locations/us-central1'),
              ('x-goog-api-client',
               'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
               'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
               'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]}
venv/lib/python3.12/site-packages/grpc/_interceptor.py:277: in __call__
    response, ignored_call = self._with_call(
        compression = None
        credentials = None
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}

        self       = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d409c5a660>
        timeout    = None
        wait_for_ready = None
venv/lib/python3.12/site-packages/grpc/_interceptor.py:332: in _with_call
    return call.result(), call
           ^^^^^^^^^^^^^
        call       = <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.PERMISSION_DENIED
	details = "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4004:c19::5f%5D:443 {grpc_message:"Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.", grpc_status:7}"
>
        client_call_details = _ClientCallDetails(method='/google.cloud.aiplatform.v1.ModelService/UploadModel', timeout=None, metadata=[('x-goog-request-params', 'parent=projects/test-project/locations/us-central1'), ('x-goog-api-client', 'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')], credentials=None, wait_for_ready=None, compression=None)
        compression = None
        continuation = <function _UnaryUnaryMultiCallable._with_call.<locals>.continuation at 0x78d409c814e0>
        credentials = None
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}

        self       = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d409c5a660>
        timeout    = None
        wait_for_ready = None
venv/lib/python3.12/site-packages/grpc/_channel.py:440: in result
    raise self
        self       = <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.PERMISSION_DENIED
	details = "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4004:c19::5f%5D:443 {grpc_message:"Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.", grpc_status:7}"
>
        timeout    = None
venv/lib/python3.12/site-packages/grpc/_interceptor.py:315: in continuation
    response, call = self._thunk(new_method).with_call(
        client_call_details = _ClientCallDetails(method='/google.cloud.aiplatform.v1.ModelService/UploadModel', timeout=None, metadata=[('x-goog-request-params', 'parent=projects/test-project/locations/us-central1'), ('x-goog-api-client', 'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')], credentials=None, wait_for_ready=None, compression=None)
        new_compression = None
        new_credentials = None
        new_details = _ClientCallDetails(method='/google.cloud.aiplatform.v1.ModelService/UploadModel', timeout=None, metadata=[('x-goog-request-params', 'parent=projects/test-project/locations/us-central1'), ('x-goog-api-client', 'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')], credentials=None, wait_for_ready=None, compression=None)
        new_metadata = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        new_method = '/google.cloud.aiplatform.v1.ModelService/UploadModel'
        new_timeout = None
        new_wait_for_ready = None
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}

        self       = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d409c5a660>
venv/lib/python3.12/site-packages/grpc/_channel.py:1195: in with_call
    return _end_unary_response_blocking(state, call, True, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        call       = <grpc._cython.cygrpc.SegregatedCall object at 0x78d403ba2dc0>
        compression = None
        credentials = None
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}

        self       = <grpc._channel._UnaryUnaryMultiCallable object at 0x78d404228210>
        state      = <grpc._channel._RPCState object at 0x78d409c65760>
        timeout    = None
        wait_for_ready = None
venv/lib/python3.12/site-packages/grpc/_channel.py:1009: in _end_unary_response_blocking
    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:
E   	status = StatusCode.PERMISSION_DENIED
E   	details = "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
E   	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4004:c19::5f%5D:443 {grpc_message:"Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.", grpc_status:7}"
E   >
        call       = <grpc._cython.cygrpc.SegregatedCall object at 0x78d403ba2dc0>
        deadline   = None
        state      = <grpc._channel._RPCState object at 0x78d409c65760>
        with_call  = True

The above exception was the direct cause of the following exception:
tests/vertex/test_fine_tuning_pipeline.py:320: in test_register_tuned_model_with_metadata
    metadata = await fine_tuning_pipeline.register_tuned_model(
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2effb0>
        result     = TuningJobResult(job_id='test-job-456',
                job_name='test-job-456-full',
                status=<TuningJobStatus.SUCCEEDED: 'succeeded'>,
                tuned_model_uri='gs://test-bucket/tuned-enhanced',
                metrics={'eval_accuracy': 0.94,
                         'eval_loss': 0.2,
                         'training_loss': 0.18},
                start_time=None,
                end_time=None,
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message=None)
        sample_tuning_config = TuningJobConfig(name='test-tuning-job',
                job_name='test-tuning-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                        validation_uri='gs://test-bucket/validation-data.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=20,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                     batch_size=32,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='test-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=['project:test', 'model:gemini'])
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2effb0>,)
        context    = None
        func       = <function FineTuningPipeline.register_tuned_model at 0x78d40a64b920>
        kwargs     = {'config': TuningJobConfig(name='test-tuning-job',
                           job_name='test-tuning-job-full',
                           base_model='gemini-pro',
                           tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                           dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                                   validation_uri='gs://test-bucket/validation-data.jsonl',
                                                   test_uri=None,
                                                   num_train_samples=100,
                                                   num_val_samples=20,
                                                   format='jsonl'),
                           hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                                batch_size=32,
                                                                num_epochs=3,
                                                                warmup_steps=100,
                                                                weight_decay=0.01,
                                                                max_seq_length=2048,
                                                                gradient_accumulation_steps=1,
                                                                scheduler='linear',
                                                                optimizer='adamw',
                                                                lora_r=8,
                                                                lora_alpha=16,
                                                                lora_dropout=0.05),
                           rlhf_config=None,
                           distillation_config=None,
                           output_model_name='test-tuned-model',
                           output_model_version='1.0.0',
                           machine_type='n1-highmem-8',
                           accelerator_type='NVIDIA_TESLA_T4',
                           accelerator_count=1,
                           max_run_time_hours=24,
                           enable_checkpointing=True,
                           checkpoint_frequency=500,
                           enable_early_stopping=True,
                           early_stopping_patience=3,
                           tags=['project:test', 'model:gemini']),
 'result': TuningJobResult(job_id='test-job-456',
                           job_name='test-job-456-full',
                           status=<TuningJobStatus.SUCCEEDED: 'succeeded'>,
                           tuned_model_uri='gs://test-bucket/tuned-enhanced',
                           metrics={'eval_accuracy': 0.94,
                                    'eval_loss': 0.2,
                                    'training_loss': 0.18},
                           start_time=None,
                           end_time=None,
                           duration_seconds=0.0,
                           vertex_ai_job_id=None,
                           error_message=None)}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.register_tuned_model'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:894: in register_tuned_model
    model = await self.model_registry.upload_model(metadata)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = TuningJobConfig(name='test-tuning-job',
                job_name='test-tuning-job-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training-data.jsonl',
                                        validation_uri='gs://test-bucket/validation-data.jsonl',
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=20,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.001,
                                                     batch_size=32,
                                                     num_epochs=3,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='test-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=['project:test', 'model:gemini'])
        metadata   = ModelMetadata(name='test-tuned-model',
              display_name='test-tuned-model-v1.0.0',
              version='1.0.0',
              description='Fine-tuned gemini-pro using supervised',
              source=<ModelSource.CUSTOM_TRAINING: 'custom'>,
              artifact_uri='gs://test-bucket/tuned-enhanced',
              serving_container_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
              deployment_stage=<DeploymentStage.DEVELOPMENT: 'development'>,
              base_model='gemini-pro',
              performance_metrics={'eval_accuracy': 0.94,
                                   'eval_loss': 0.2,
                                   'training_loss': 0.18},
              cost_metrics={},
              tags=['project:test', 'model:gemini', 'supervised', 'fine-tuned'],
              created_at=datetime.datetime(2025, 11, 4, 14, 58, 33, 388604),
              updated_at=datetime.datetime(2025, 11, 4, 14, 58, 33, 388609),
              created_by='genesis',
              parent_version=None,
              vertex_ai_resource_name=None,
              custom_metadata={})
        result     = TuningJobResult(job_id='test-job-456',
                job_name='test-job-456-full',
                status=<TuningJobStatus.SUCCEEDED: 'succeeded'>,
                tuned_model_uri='gs://test-bucket/tuned-enhanced',
                metrics={'eval_accuracy': 0.94,
                         'eval_loss': 0.2,
                         'training_loss': 0.18},
                start_time=None,
                end_time=None,
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message=None)
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2effb0>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_registry.ModelRegistry object at 0x78d409fdb0e0>,
 ModelMetadata(name='test-tuned-model',
               display_name='test-tuned-model-v1.0.0',
               version='1.0.0',
               description='Fine-tuned gemini-pro using supervised',
               source=<ModelSource.CUSTOM_TRAINING: 'custom'>,
               artifact_uri='gs://test-bucket/tuned-enhanced',
               serving_container_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
               deployment_stage=<DeploymentStage.DEVELOPMENT: 'development'>,
               base_model='gemini-pro',
               performance_metrics={'eval_accuracy': 0.94,
                                    'eval_loss': 0.2,
                                    'training_loss': 0.18},
               cost_metrics={},
               tags=['project:test',
                     'model:gemini',
                     'supervised',
                     'fine-tuned'],
               created_at=datetime.datetime(2025, 11, 4, 14, 58, 33, 388604),
               updated_at=datetime.datetime(2025, 11, 4, 14, 58, 33, 388609),
               created_by='genesis',
               parent_version=None,
               vertex_ai_resource_name=None,
               custom_metadata={}))
        context    = None
        func       = <function ModelRegistry.upload_model at 0x78d40a648e00>
        kwargs     = {}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_registry.upload_model'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_registry.py:326: in upload_model
    model = Model.upload(
        deployment_timeout = 1800
        env_vars   = {'GENESIS_DEPLOYMENT_STAGE': 'development',
 'GENESIS_MODEL_NAME': 'test-tuned-model',
 'GENESIS_MODEL_VERSION': '1.0.0'}
        labels     = None
        metadata   = ModelMetadata(name='test-tuned-model',
              display_name='test-tuned-model-v1.0.0',
              version='1.0.0',
              description='Fine-tuned gemini-pro using supervised',
              source=<ModelSource.CUSTOM_TRAINING: 'custom'>,
              artifact_uri='gs://test-bucket/tuned-enhanced',
              serving_container_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
              deployment_stage=<DeploymentStage.DEVELOPMENT: 'development'>,
              base_model='gemini-pro',
              performance_metrics={'eval_accuracy': 0.94,
                                   'eval_loss': 0.2,
                                   'training_loss': 0.18},
              cost_metrics={},
              tags=['project:test', 'model:gemini', 'supervised', 'fine-tuned'],
              created_at=datetime.datetime(2025, 11, 4, 14, 58, 33, 388604),
              updated_at=datetime.datetime(2025, 11, 4, 14, 58, 33, 388609),
              created_by='genesis',
              parent_version=None,
              vertex_ai_resource_name=None,
              custom_metadata={})
        safe_tag   = 'fine_tuned'
        self       = <infrastructure.vertex_ai.model_registry.ModelRegistry object at 0x78d409fdb0e0>
        serving_container_env_vars = None
        serving_container_health_route = '/health'
        serving_container_ports = [8080]
        serving_container_predict_route = '/predict'
        shared_memory_mb = 16384
        start_time = 1762268313.388593
        sync       = True
        tag        = 'fine-tuned'
        vertex_labels = {'genesis_source': 'custom',
 'genesis_stage': 'development',
 'genesis_version': '1_0_0',
 'tag_fine_tuned': 'true',
 'tag_model:gemini': 'true',
 'tag_project:test': 'true',
 'tag_supervised': 'true'}
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:862: in wrapper
    return method(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<class 'google.cloud.aiplatform.models.Model'>,)
        bind_future_to_self = True
        bound_args = <BoundArguments (cls=<class 'google.cloud.aiplatform.models.Model'>, serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest', artifact_uri='gs://test-bucket/tuned-enhanced', serving_container_predict_route='/predict', serving_container_health_route='/health', description='Fine-tuned gemini-pro using supervised', serving_container_environment_variables={'GENESIS_MODEL_NAME': 'test-tuned-model', 'GENESIS_MODEL_VERSION': '1.0.0', 'GENESIS_DEPLOYMENT_STAGE': 'development'}, serving_container_ports=[8080], display_name='test-tuned-model-v1.0.0', labels={'genesis_version': '1_0_0', 'genesis_source': 'custom', 'genesis_stage': 'development', 'tag_project:test': 'true', 'tag_model:gemini': 'true', 'tag_supervised': 'true', 'tag_fine_tuned': 'true'}, serving_container_deployment_timeout=1800, serving_container_shared_memory_size_mb=16384)>
        calling_object_latest_future = None
        construct_object_on_arg = None
        kwargs     = {'artifact_uri': 'gs://test-bucket/tuned-enhanced',
 'description': 'Fine-tuned gemini-pro using supervised',
 'display_name': 'test-tuned-model-v1.0.0',
 'labels': {'genesis_source': 'custom',
            'genesis_stage': 'development',
            'genesis_version': '1_0_0',
            'tag_fine_tuned': 'true',
            'tag_model:gemini': 'true',
            'tag_project:test': 'true',
            'tag_supervised': 'true'},
 'serving_container_deployment_timeout': 1800,
 'serving_container_environment_variables': {'GENESIS_DEPLOYMENT_STAGE': 'development',
                                             'GENESIS_MODEL_NAME': 'test-tuned-model',
                                             'GENESIS_MODEL_VERSION': '1.0.0'},
 'serving_container_health_route': '/health',
 'serving_container_image_uri': 'us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest',
 'serving_container_ports': [8080],
 'serving_container_predict_route': '/predict',
 'serving_container_shared_memory_size_mb': 16384}
        method     = <function Model.upload at 0x78d40a813ec0>
        return_input_arg = None
        self       = None
        sync       = True
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:5708: in upload
    lro = api_client.upload_model(
        api_client = <google.cloud.aiplatform.utils.ModelClientWithOverride object at 0x78d409c59f40>
        appended_user_agent = None
        artifact_uri = 'gs://test-bucket/tuned-enhanced'
        base_model_source = None
        cls        = <class 'google.cloud.aiplatform.models.Model'>
        container_spec = image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
env {
  name: "GENESIS_MODEL_NAME"
  value: "test-tuned-model"
}
env {
  name: "GENESIS_MODEL_VERSION"
  value: "1.0.0"
}
env {
  name: "GENESIS_DEPLOYMENT_STAGE"
  value: "development"
}
ports {
  container_port: 8080
}
predict_route: "/predict"
health_route: "/health"
deployment_timeout {
  seconds: 1800
}
shared_memory_size_mb: 16384

        credentials = None
        deployment_timeout = seconds: 1800

        description = 'Fine-tuned gemini-pro using supervised'
        display_name = 'test-tuned-model-v1.0.0'
        encryption_spec = None
        encryption_spec_key_name = None
        env        = [name: "GENESIS_MODEL_NAME"
value: "test-tuned-model"
,
 name: "GENESIS_MODEL_VERSION"
value: "1.0.0"
,
 name: "GENESIS_DEPLOYMENT_STAGE"
value: "development"
]
        explanation_metadata = None
        explanation_parameters = None
        grpc_ports = None
        health_probe = None
        instance_schema_uri = None
        is_default_version = True
        labels     = {'genesis_source': 'custom',
 'genesis_stage': 'development',
 'genesis_version': '1_0_0',
 'tag_fine_tuned': 'true',
 'tag_model:gemini': 'true',
 'tag_project:test': 'true',
 'tag_supervised': 'true'}
        local_model = None
        location   = None
        managed_model = display_name: "test-tuned-model-v1.0.0"
description: "Fine-tuned gemini-pro using supervised"
container_spec {
  image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
  env {
    name: "GENESIS_MODEL_NAME"
    value: "test-tuned-model"
  }
  env {
    name: "GENESIS_MODEL_VERSION"
    value: "1.0.0"
  }
  env {
    name: "GENESIS_DEPLOYMENT_STAGE"
    value: "development"
  }
  ports {
    container_port: 8080
  }
  predict_route: "/predict"
  health_route: "/health"
  deployment_timeout {
    seconds: 1800
  }
  shared_memory_size_mb: 16384
}
labels {
  key: "tag_supervised"
  value: "true"
}
labels {
  key: "tag_project:test"
  value: "true"
}
labels {
  key: "tag_model:gemini"
  value: "true"
}
labels {
  key: "tag_fine_tuned"
  value: "true"
}
labels {
  key: "genesis_version"
  value: "1_0_0"
}
labels {
  key: "genesis_stage"
  value: "development"
}
labels {
  key: "genesis_source"
  value: "custom"
}
artifact_uri: "gs://test-bucket/tuned-enhanced"
version_aliases: "default"

        model_garden_source_model_name = None
        model_garden_source_model_version_id = None
        model_id   = None
        model_predict_schemata = None
        parameters_schema_uri = None
        parent_model = None
        ports      = [container_port: 8080
]
        prediction_schema_uri = None
        project    = None
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}

        serving_container_args = None
        serving_container_command = None
        serving_container_deployment_timeout = 1800
        serving_container_environment_variables = {'GENESIS_DEPLOYMENT_STAGE': 'development',
 'GENESIS_MODEL_NAME': 'test-tuned-model',
 'GENESIS_MODEL_VERSION': '1.0.0'}
        serving_container_grpc_ports = None
        serving_container_health_probe_exec = None
        serving_container_health_probe_period_seconds = None
        serving_container_health_probe_timeout_seconds = None
        serving_container_health_route = '/health'
        serving_container_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest'
        serving_container_invoke_route_prefix = None
        serving_container_ports = [8080]
        serving_container_predict_route = '/predict'
        serving_container_shared_memory_size_mb = 16384
        serving_container_startup_probe_exec = None
        serving_container_startup_probe_period_seconds = None
        serving_container_startup_probe_timeout_seconds = None
        staging_bucket = None
        startup_probe = None
        sync       = True
        upload_request_timeout = None
        version_aliases = ['default']
        version_description = None
venv/lib/python3.12/site-packages/google/cloud/aiplatform_v1/services/model_service/client.py:1002: in upload_model
    response = rpc(
        flattened_params = [None, None]
        has_flattened_params = False
        metadata   = (('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),)
        model      = None
        parent     = None
        request    = parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}

        retry      = <_MethodDefault._DEFAULT_VALUE: <object object at 0x78d41bf2d210>>
        rpc        = <google.api_core.gapic_v1.method._GapicCallable object at 0x78d409c5a6f0>
        self       = <google.cloud.aiplatform_v1.services.model_service.client.ModelServiceClient object at 0x78d409c59fa0>
        timeout    = None
venv/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131: in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}
,)
        compression = None
        kwargs     = {'metadata': [('x-goog-request-params',
               'parent=projects/test-project/locations/us-central1'),
              ('x-goog-api-client',
               'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
               'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
               'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]}
        metadata   = [('x-goog-request-params',
  'parent=projects/test-project/locations/us-central1'),
 ('x-goog-api-client',
  'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
  'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
  'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]
        retry      = None
        self       = <google.api_core.gapic_v1.method._GapicCallable object at 0x78d409c5a6f0>
        timeout    = None
        wrapped_func = <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x78d409d09d00>
venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:77: in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
E   google.api_core.exceptions.PermissionDenied: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
E   domain: "googleapis.com"
E   metadata {
E     key: "service"
E     value: "aiplatform.googleapis.com"
E   }
E   metadata {
E     key: "serviceTitle"
E     value: "Vertex AI API"
E   }
E   metadata {
E     key: "containerInfo"
E     value: "test-project"
E   }
E   metadata {
E     key: "consumer"
E     value: "projects/test-project"
E   }
E   metadata {
E     key: "activationUrl"
E     value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
E   }
E   , locale: "en-US"
E   message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
E   , links {
E     description: "Google developers console API activation"
E     url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
E   }
E   ]
        args       = (parent: "projects/test-project/locations/us-central1"
model {
  display_name: "test-tuned-model-v1.0.0"
  description: "Fine-tuned gemini-pro using supervised"
  container_spec {
    image_uri: "us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu:latest"
    env {
      name: "GENESIS_MODEL_NAME"
      value: "test-tuned-model"
    }
    env {
      name: "GENESIS_MODEL_VERSION"
      value: "1.0.0"
    }
    env {
      name: "GENESIS_DEPLOYMENT_STAGE"
      value: "development"
    }
    ports {
      container_port: 8080
    }
    predict_route: "/predict"
    health_route: "/health"
    deployment_timeout {
      seconds: 1800
    }
    shared_memory_size_mb: 16384
  }
  labels {
    key: "tag_supervised"
    value: "true"
  }
  labels {
    key: "tag_project:test"
    value: "true"
  }
  labels {
    key: "tag_model:gemini"
    value: "true"
  }
  labels {
    key: "tag_fine_tuned"
    value: "true"
  }
  labels {
    key: "genesis_version"
    value: "1_0_0"
  }
  labels {
    key: "genesis_stage"
    value: "development"
  }
  labels {
    key: "genesis_source"
    value: "custom"
  }
  artifact_uri: "gs://test-bucket/tuned-enhanced"
  version_aliases: "default"
}
,)
        callable_  = <grpc._interceptor._UnaryUnaryMultiCallable object at 0x78d409c5a660>
        kwargs     = {'metadata': [('x-goog-request-params',
               'parent=projects/test-project/locations/us-central1'),
              ('x-goog-api-client',
               'model-builder/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper '
               'gl-python/3.12.3 grpc/1.75.1 gax/2.27.0 '
               'gapic/1.122.0+top_google_constructor_method+google.cloud.aiplatform.base.wrapper')]}
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_registry:Uploading model to Vertex AI: test-tuned-model v1.0.0 (stage=development)
E0000 00:00:1762268313.389597  512909 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
ERROR:vertex_ai.model_registry:Model upload failed: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_registry:model_registry.py:319 Uploading model to Vertex AI: test-tuned-model v1.0.0 (stage=development)
ERROR    vertex_ai.model_registry:model_registry.py:362 Model upload failed: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
___________________ test_tuning_with_custom_hyperparameters ____________________
tests/vertex/test_fine_tuning_pipeline.py:396: in test_tuning_with_custom_hyperparameters
    job = await fine_tuning_pipeline.submit_tuning_job(
        HyperparameterConfig = <class 'infrastructure.vertex_ai.fine_tuning_pipeline.HyperparameterConfig'>
        config     = TuningJobConfig(name='custom-hyperparams',
                job_name='custom-hyperparams-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.0005,
                                                     batch_size=64,
                                                     num_epochs=5,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='custom-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2ee150>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2ee150>,)
        context    = None
        func       = <function FineTuningPipeline.submit_tuning_job at 0x78d40a64b4c0>
        kwargs     = {'config': TuningJobConfig(name='custom-hyperparams',
                           job_name='custom-hyperparams-full',
                           base_model='gemini-pro',
                           tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                           dataset=TrainingDataset(train_uri='gs://test-bucket/training.jsonl',
                                                   validation_uri=None,
                                                   test_uri=None,
                                                   num_train_samples=100,
                                                   num_val_samples=0,
                                                   format='jsonl'),
                           hyperparameters=HyperparameterConfig(learning_rate=0.0005,
                                                                batch_size=64,
                                                                num_epochs=5,
                                                                warmup_steps=100,
                                                                weight_decay=0.01,
                                                                max_seq_length=2048,
                                                                gradient_accumulation_steps=1,
                                                                scheduler='linear',
                                                                optimizer='adamw',
                                                                lora_r=8,
                                                                lora_alpha=16,
                                                                lora_dropout=0.05),
                           rlhf_config=None,
                           distillation_config=None,
                           output_model_name='custom-tuned-model',
                           output_model_version='1.0.0',
                           machine_type='n1-highmem-8',
                           accelerator_type='NVIDIA_TESLA_T4',
                           accelerator_count=1,
                           max_run_time_hours=24,
                           enable_checkpointing=True,
                           checkpoint_frequency=500,
                           enable_early_stopping=True,
                           early_stopping_patience=3,
                           tags=[]),
 'wait_for_completion': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.submit_tuning_job'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:632: in submit_tuning_job
    vertex_job = await self._submit_supervised_job(config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = TuningJobConfig(name='custom-hyperparams',
                job_name='custom-hyperparams-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.0005,
                                                     batch_size=64,
                                                     num_epochs=5,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='custom-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        job_id     = 'custom-hyperparams-full'
        progress_callback = None
        result     = TuningJobResult(job_id='custom-hyperparams-full',
                job_name='custom-hyperparams-full',
                status=<TuningJobStatus.FAILED: 'failed'>,
                tuned_model_uri=None,
                metrics={},
                start_time=datetime.datetime(2025, 11, 4, 14, 58, 34, 49632),
                end_time=datetime.datetime(2025, 11, 4, 14, 58, 34, 49691),
                duration_seconds=0.0,
                vertex_ai_job_id=None,
                error_message='staging_bucket should be passed to '
                              'CustomJob.from_local_script or should be set '
                              'using '
                              "aiplatform.init(staging_bucket='gs://my-bucket')")
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2ee150>
        start_time = 1762268314.0495257
        wait_for_completion = False
infrastructure/vertex_ai/fine_tuning_pipeline.py:693: in _submit_supervised_job
    job = CustomJob.from_local_script(
        config     = TuningJobConfig(name='custom-hyperparams',
                job_name='custom-hyperparams-full',
                base_model='gemini-pro',
                tuning_type=<TuningType.SUPERVISED: 'supervised'>,
                dataset=TrainingDataset(train_uri='gs://test-bucket/training.jsonl',
                                        validation_uri=None,
                                        test_uri=None,
                                        num_train_samples=100,
                                        num_val_samples=0,
                                        format='jsonl'),
                hyperparameters=HyperparameterConfig(learning_rate=0.0005,
                                                     batch_size=64,
                                                     num_epochs=5,
                                                     warmup_steps=100,
                                                     weight_decay=0.01,
                                                     max_seq_length=2048,
                                                     gradient_accumulation_steps=1,
                                                     scheduler='linear',
                                                     optimizer='adamw',
                                                     lora_r=8,
                                                     lora_alpha=16,
                                                     lora_dropout=0.05),
                rlhf_config=None,
                distillation_config=None,
                output_model_name='custom-tuned-model',
                output_model_version='1.0.0',
                machine_type='n1-highmem-8',
                accelerator_type='NVIDIA_TESLA_T4',
                accelerator_count=1,
                max_run_time_hours=24,
                enable_checkpointing=True,
                checkpoint_frequency=500,
                enable_early_stopping=True,
                early_stopping_patience=3,
                tags=[])
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a2ee150>
        training_args = {'base_model': 'gemini-pro',
 'batch_size': 64,
 'checkpoint_frequency': 500,
 'early_stopping': True,
 'early_stopping_patience': 3,
 'learning_rate': 0.0005,
 'max_seq_length': 2048,
 'num_epochs': 5,
 'output_dir': 'gs://test-project-tuning-outputs/custom-hyperparams-full',
 'train_data': 'gs://test-bucket/training.jsonl',
 'validation_data': None}
venv/lib/python3.12/site-packages/google/cloud/aiplatform/jobs.py:2085: in from_local_script
    raise RuntimeError(
E   RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
        accelerator_count = 1
        accelerator_type = 'NVIDIA_TESLA_T4'
        args       = ('{"base_model": "gemini-pro", "train_data": '
 '"gs://test-bucket/training.jsonl", "validation_data": null, "learning_rate": '
 '0.0005, "batch_size": 64, "num_epochs": 5, "max_seq_length": 2048, '
 '"output_dir": "gs://test-project-tuning-outputs/custom-hyperparams-full", '
 '"checkpoint_frequency": 500, "early_stopping": true, '
 '"early_stopping_patience": 3}')
        base_output_dir = None
        boot_disk_size_gb = 100
        boot_disk_type = 'pd-ssd'
        cls        = <class 'google.cloud.aiplatform.jobs.CustomJob'>
        container_uri = 'gcr.io/test-project/training-container:latest'
        credentials = None
        display_name = 'custom-hyperparams-full'
        enable_autolog = False
        encryption_spec_key_name = None
        environment_variables = None
        labels     = None
        location   = 'us-central1'
        machine_type = 'n1-highmem-8'
        persistent_resource_id = None
        project    = 'test-project'
        reduction_server_container_uri = None
        reduction_server_machine_type = None
        reduction_server_replica_count = 0
        replica_count = 1
        requirements = None
        script_path = 'training_scripts/supervised_finetune.py'
        staging_bucket = None
        tpu_topology = None
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Submitting tuning job: custom-hyperparams-full (type=supervised, base_model=gemini-pro)
ERROR:vertex_ai.fine_tuning:Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:614 Submitting tuning job: custom-hyperparams-full (type=supervised, base_model=gemini-pro)
ERROR    vertex_ai.fine_tuning:fine_tuning_pipeline.py:668 Tuning job submission failed: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
________________ test_dataset_preparation_with_validation_split ________________
tests/vertex/test_fine_tuning_pipeline.py:423: in test_dataset_preparation_with_validation_split
    dataset = await fine_tuning_pipeline.prepare_se_darwin_dataset(
        archive_data = {'trajectories': [{'code': 'def code_0(): return 0',
                   'improvement_metrics': {'score': 0.8},
                   'iteration': 0,
                   'test_results': [True, True, True]},
                  {'code': 'def code_1(): return 1',
                   'improvement_metrics': {'score': 0.81},
                   'iteration': 1,
                   'test_results': [True, True, True]},
                  {'code': 'def code_2(): return 2',
                   'improvement_metrics': {'score': 0.8200000000000001},
                   'iteration': 2,
                   'test_results': [True, True, True]},
                  {'code': 'def code_3(): return 3',
                   'improvement_metrics': {'score': 0.8300000000000001},
                   'iteration': 3,
                   'test_results': [True, True, True]},
                  {'code': 'def code_4(): return 4',
                   'improvement_metrics': {'score': 0.8400000000000001},
                   'iteration': 4,
                   'test_results': [True, True, True]},
                  {'code': 'def code_5(): return 5',
                   'improvement_metrics': {'score': 0.8500000000000001},
                   'iteration': 5,
                   'test_results': [True, True, True]},
                  {'code': 'def code_6(): return 6',
                   'improvement_metrics': {'score': 0.8600000000000001},
                   'iteration': 6,
                   'test_results': [True, True, True]},
                  {'code': 'def code_7(): return 7',
                   'improvement_metrics': {'score': 0.8700000000000001},
                   'iteration': 7,
                   'test_results': [True, True, True]},
                  {'code': 'def code_8(): return 8',
                   'improvement_metrics': {'score': 0.88},
                   'iteration': 8,
                   'test_results': [True, True, True]},
                  {'code': 'def code_9(): return 9',
                   'improvement_metrics': {'score': 0.89},
                   'iteration': 9,
                   'test_results': [True, True, True]},
                  {'code': 'def code_10(): return 10',
                   'improvement_metrics': {'score': 0.9},
                   'iteration': 10,
                   'test_results': [True, True, True]},
                  {'code': 'def code_11(): return 11',
                   'improvement_metrics': {'score': 0.91},
                   'iteration': 11,
                   'test_results': [True, True, True]},
                  {'code': 'def code_12(): return 12',
                   'improvement_metrics': {'score': 0.92},
                   'iteration': 12,
                   'test_results': [True, True, True]},
                  {'code': 'def code_13(): return 13',
                   'improvement_metrics': {'score': 0.93},
                   'iteration': 13,
                   'test_results': [True, True, True]},
                  {'code': 'def code_14(): return 14',
                   'improvement_metrics': {'score': 0.9400000000000001},
                   'iteration': 14,
                   'test_results': [True, True, True]},
                  {'code': 'def code_15(): return 15',
                   'improvement_metrics': {'score': 0.9500000000000001},
                   'iteration': 15,
                   'test_results': [True, True, True]},
                  {'code': 'def code_16(): return 16',
                   'improvement_metrics': {'score': 0.9600000000000001},
                   'iteration': 16,
                   'test_results': [True, True, True]},
                  {'code': 'def code_17(): return 17',
                   'improvement_metrics': {'score': 0.9700000000000001},
                   'iteration': 17,
                   'test_results': [True, True, True]},
                  {'code': 'def code_18(): return 18',
                   'improvement_metrics': {'score': 0.98},
                   'iteration': 18,
                   'test_results': [True, True, True]},
                  {'code': 'def code_19(): return 19',
                   'improvement_metrics': {'score': 0.99},
                   'iteration': 19,
                   'test_results': [True, True, True]},
                  {'code': 'def code_20(): return 20',
                   'improvement_metrics': {'score': 1.0},
                   'iteration': 20,
                   'test_results': [True, True, True]},
                  {'code': 'def code_21(): return 21',
                   'improvement_metrics': {'score': 1.01},
                   'iteration': 21,
                   'test_results': [True, True, True]},
                  {'code': 'def code_22(): return 22',
                   'improvement_metrics': {'score': 1.02},
                   'iteration': 22,
                   'test_results': [True, True, True]},
                  {'code': 'def code_23(): return 23',
                   'improvement_metrics': {'score': 1.03},
                   'iteration': 23,
                   'test_results': [True, True, True]},
                  {'code': 'def code_24(): return 24',
                   'improvement_metrics': {'score': 1.04},
                   'iteration': 24,
                   'test_results': [True, True, True]},
                  {'code': 'def code_25(): return 25',
                   'improvement_metrics': {'score': 1.05},
                   'iteration': 25,
                   'test_results': [True, True, True]},
                  {'code': 'def code_26(): return 26',
                   'improvement_metrics': {'score': 1.06},
                   'iteration': 26,
                   'test_results': [True, True, True]},
                  {'code': 'def code_27(): return 27',
                   'improvement_metrics': {'score': 1.07},
                   'iteration': 27,
                   'test_results': [True, True, True]},
                  {'code': 'def code_28(): return 28',
                   'improvement_metrics': {'score': 1.08},
                   'iteration': 28,
                   'test_results': [True, True, True]},
                  {'code': 'def code_29(): return 29',
                   'improvement_metrics': {'score': 1.09},
                   'iteration': 29,
                   'test_results': [True, True, True]},
                  {'code': 'def code_30(): return 30',
                   'improvement_metrics': {'score': 1.1},
                   'iteration': 30,
                   'test_results': [True, True, True]},
                  {'code': 'def code_31(): return 31',
                   'improvement_metrics': {'score': 1.11},
                   'iteration': 31,
                   'test_results': [True, True, True]},
                  {'code': 'def code_32(): return 32',
                   'improvement_metrics': {'score': 1.12},
                   'iteration': 32,
                   'test_results': [True, True, True]},
                  {'code': 'def code_33(): return 33',
                   'improvement_metrics': {'score': 1.1300000000000001},
                   'iteration': 33,
                   'test_results': [True, True, True]},
                  {'code': 'def code_34(): return 34',
                   'improvement_metrics': {'score': 1.1400000000000001},
                   'iteration': 34,
                   'test_results': [True, True, True]},
                  {'code': 'def code_35(): return 35',
                   'improvement_metrics': {'score': 1.1500000000000001},
                   'iteration': 35,
                   'test_results': [True, True, True]},
                  {'code': 'def code_36(): return 36',
                   'improvement_metrics': {'score': 1.1600000000000001},
                   'iteration': 36,
                   'test_results': [True, True, True]},
                  {'code': 'def code_37(): return 37',
                   'improvement_metrics': {'score': 1.17},
                   'iteration': 37,
                   'test_results': [True, True, True]},
                  {'code': 'def code_38(): return 38',
                   'improvement_metrics': {'score': 1.1800000000000002},
                   'iteration': 38,
                   'test_results': [True, True, True]},
                  {'code': 'def code_39(): return 39',
                   'improvement_metrics': {'score': 1.19},
                   'iteration': 39,
                   'test_results': [True, True, True]},
                  {'code': 'def code_40(): return 40',
                   'improvement_metrics': {'score': 1.2000000000000002},
                   'iteration': 40,
                   'test_results': [True, True, True]},
                  {'code': 'def code_41(): return 41',
                   'improvement_metrics': {'score': 1.21},
                   'iteration': 41,
                   'test_results': [True, True, True]},
                  {'code': 'def code_42(): return 42',
                   'improvement_metrics': {'score': 1.22},
                   'iteration': 42,
                   'test_results': [True, True, True]},
                  {'code': 'def code_43(): return 43',
                   'improvement_metrics': {'score': 1.23},
                   'iteration': 43,
                   'test_results': [True, True, True]},
                  {'code': 'def code_44(): return 44',
                   'improvement_metrics': {'score': 1.24},
                   'iteration': 44,
                   'test_results': [True, True, True]},
                  {'code': 'def code_45(): return 45',
                   'improvement_metrics': {'score': 1.25},
                   'iteration': 45,
                   'test_results': [True, True, True]},
                  {'code': 'def code_46(): return 46',
                   'improvement_metrics': {'score': 1.26},
                   'iteration': 46,
                   'test_results': [True, True, True]},
                  {'code': 'def code_47(): return 47',
                   'improvement_metrics': {'score': 1.27},
                   'iteration': 47,
                   'test_results': [True, True, True]},
                  {'code': 'def code_48(): return 48',
                   'improvement_metrics': {'score': 1.28},
                   'iteration': 48,
                   'test_results': [True, True, True]},
                  {'code': 'def code_49(): return 49',
                   'improvement_metrics': {'score': 1.29},
                   'iteration': 49,
                   'test_results': [True, True, True]}]}
        archive_path = PosixPath('/tmp/tmpo_fowe9z/archive-split.json')
        f          = <_io.TextIOWrapper name='/tmp/tmpo_fowe9z/archive-split.json' mode='w' encoding='UTF-8'>
        fine_tuning_pipeline = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29a4e0>
        tmpdir     = '/tmp/tmpo_fowe9z'
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29a4e0>,)
        context    = None
        func       = <function FineTuningPipeline.prepare_se_darwin_dataset at 0x78d40a64b240>
        kwargs     = {'archive_path': '/tmp/tmpo_fowe9z/archive-split.json',
 'max_trajectories': 50,
 'output_gcs_uri': 'gs://test-bucket/split-dataset'}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'fine_tuning.prepare_se_darwin_dataset'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/fine_tuning_pipeline.py:439: in prepare_se_darwin_dataset
    raise ValueError(f"No valid training examples found in {archive_path}")
E   ValueError: No valid training examples found in /tmp/tmpo_fowe9z/archive-split.json
        archive_dir = PosixPath('/tmp/tmpo_fowe9z/archive-split.json')
        archive_path = '/tmp/tmpo_fowe9z/archive-split.json'
        max_trajectories = 50
        min_test_pass_rate = 0.7
        output_gcs_uri = 'gs://test-bucket/split-dataset'
        quality_threshold = 0.8
        self       = <infrastructure.vertex_ai.fine_tuning_pipeline.FineTuningPipeline object at 0x78d40a29a4e0>
        training_examples = []
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.fine_tuning:FineTuningPipeline initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:355 FineTuningPipeline initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.fine_tuning:Preparing SE-Darwin dataset from /tmp/tmpo_fowe9z/archive-split.json → gs://test-bucket/split-dataset
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.fine_tuning:fine_tuning_pipeline.py:392 Preparing SE-Darwin dataset from /tmp/tmpo_fowe9z/archive-split.json → gs://test-bucket/split-dataset
_________________________ test_create_endpoint_success _________________________
tests/vertex/test_model_endpoints.py:56: in test_create_endpoint_success
    endpoint = await model_endpoints.create_endpoint(
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a32a030>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a32a030>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a33acc0> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a32a030>
        start_time = 1762268314.1495247
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a33acc0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a33acc0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a33acc0> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
E0000 00:00:1762268314.152780  512971 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
______________________ test_create_endpoint_with_network _______________________
tests/vertex/test_model_endpoints.py:78: in test_create_endpoint_with_network
    endpoint = await model_endpoints.create_endpoint(config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        config     = EndpointConfig(name='private-endpoint',
               display_name='Private Endpoint',
               description='VPC endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='projects/test-project/global/networks/custom-vpc',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=False,
               enable_access_logging=False,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'access': 'private',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0'})
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a29a360>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a29a360>,
 EndpointConfig(name='private-endpoint',
                display_name='Private Endpoint',
                description='VPC endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='projects/test-project/global/networks/custom-vpc',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=False,
                enable_access_logging=False,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'access': 'private',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='private-endpoint',
               display_name='Private Endpoint',
               description='VPC endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='projects/test-project/global/networks/custom-vpc',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=False,
               enable_access_logging=False,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'access': 'private',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a2ede80> is waiting for upstream dependencies to complete.
        labels     = {'access': 'private', 'genesis_endpoint': 'true', 'genesis_version': '1_0_0'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a29a360>
        start_time = 1762268314.2437296
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a2ede80> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a2ede80> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a2ede80> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: private-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
E0000 00:00:1762268314.245234  512973 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: private-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
__________________________ test_deploy_model_success ___________________________
tests/vertex/test_model_endpoints.py:86: in test_deploy_model_success
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a3f2bd0>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a3f2bd0>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862780> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a3f2bd0>
        start_time = 1762268314.3722563
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862780> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862780> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862780> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
______________________ test_deploy_model_with_autoscaling ______________________
tests/vertex/test_model_endpoints.py:106: in test_deploy_model_with_autoscaling
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8dc7a0>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8dc7a0>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fc03e0> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8dc7a0>
        start_time = 1762268314.47043
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fc03e0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fc03e0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fc03e0> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
_____________________________ test_predict_success _____________________________
tests/vertex/test_model_endpoints.py:125: in test_predict_success
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41f3c9d00>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41f3c9d00>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862180> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41f3c9d00>
        start_time = 1762268314.605909
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862180> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862180> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c862180> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
______________________________ test_predict_batch ______________________________
tests/vertex/test_model_endpoints.py:149: in test_predict_batch
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a047a10>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a047a10>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a024740> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a047a10>
        start_time = 1762268314.6848662
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a024740> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a024740> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a024740> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
_____________________ test_update_traffic_split_ab_testing _____________________
tests/vertex/test_model_endpoints.py:176: in test_update_traffic_split_ab_testing
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8ddf40>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8ddf40>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c8c2450> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8ddf40>
        start_time = 1762268314.7662985
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c8c2450> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c8c2450> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c8c2450> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
E0000 00:00:1762268314.767467  512987 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
__________________ test_update_traffic_split_gradual_rollout ___________________
tests/vertex/test_model_endpoints.py:211: in test_update_traffic_split_gradual_rollout
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff6510>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff6510>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a042480> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff6510>
        start_time = 1762268314.8477488
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a042480> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a042480> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a042480> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
_____________________________ test_undeploy_model ______________________________
tests/vertex/test_model_endpoints.py:239: in test_undeploy_model
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff6330>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff6330>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c863dd0> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff6330>
        start_time = 1762268314.9467163
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c863dd0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c863dd0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d41c863dd0> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
_____________________________ test_delete_endpoint _____________________________
tests/vertex/test_model_endpoints.py:262: in test_delete_endpoint
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409f66570>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409f66570>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fe50d0> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409f66570>
        start_time = 1762268315.0435483
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fe50d0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fe50d0> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409fe50d0> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
_____________________________ test_list_endpoints ______________________________
tests/vertex/test_model_endpoints.py:285: in test_list_endpoints
    await model_endpoints.create_endpoint(config1, sync=False)
        config1    = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        config2    = EndpointConfig(name='endpoint-2',
               display_name='Endpoint 2',
               description='Second endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={})
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8c0170>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8c0170>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a031b80> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d41c8c0170>
        start_time = 1762268315.1402447
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a031b80> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a031b80> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a031b80> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
_______________________ test_list_endpoints_with_filters _______________________
tests/vertex/test_model_endpoints.py:303: in test_list_endpoints_with_filters
    await model_endpoints.create_endpoint(config, sync=False)
        config     = EndpointConfig(name='labeled-endpoint',
               display_name='Labeled Endpoint',
               description='For filtering',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'stage': 'prod',
                       'team': 'ml'})
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409fe58b0>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test', 'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409fe58b0>,
 EndpointConfig(name='labeled-endpoint',
                display_name='Labeled Endpoint',
                description='For filtering',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'stage': 'prod',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='labeled-endpoint',
               display_name='Labeled Endpoint',
               description='For filtering',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'stage': 'prod',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d409ff8290> is waiting for upstream dependencies to complete.
        labels     = {'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'stage': 'prod',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409fe58b0>
        start_time = 1762268315.2445283
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409ff8290> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409ff8290> failed with 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d409ff8290> failed with 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: labeled-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: labeled-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
___________________________ test_get_endpoint_stats ____________________________
tests/vertex/test_model_endpoints.py:316: in test_get_endpoint_stats
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff97c0>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff97c0>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a033b60> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d409ff97c0>
        start_time = 1762268315.365728
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a033b60> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a033b60> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a033b60> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
_____________________ test_predict_with_custom_parameters ______________________
tests/vertex/test_model_endpoints.py:359: in test_predict_with_custom_parameters
    endpoint = await model_endpoints.create_endpoint(sample_endpoint_config, sync=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        model_endpoints = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a217320>
        sample_endpoint_config = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a217320>,
 EndpointConfig(name='test-endpoint',
                display_name='Test Endpoint',
                description='A test endpoint',
                machine_type='n1-standard-4',
                accelerator_type=None,
                accelerator_count=0,
                network='',
                auto_scaling=AutoScalingConfig(min_replica_count=1,
                                               max_replica_count=10,
                                               target_accelerator_duty_cycle=60,
                                               scale_down_delay_minutes=5,
                                               enable_scale_to_zero=False),
                traffic_split=None,
                enable_request_logging=True,
                enable_access_logging=True,
                enable_container_logging=True,
                dedicated_endpoint=False,
                spot_instance=False,
                labels={'environment': 'test',
                        'genesis_endpoint': 'true',
                        'genesis_version': '1_0_0',
                        'team': 'ml'}))
        context    = None
        func       = <function ModelEndpoints.create_endpoint at 0x78d40a4acc20>
        kwargs     = {'sync': False}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'model_endpoints.create_endpoint'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/model_endpoints.py:298: in create_endpoint
    self.endpoint_cache[endpoint.name] = endpoint
                        ^^^^^^^^^^^^^
        config     = EndpointConfig(name='test-endpoint',
               display_name='Test Endpoint',
               description='A test endpoint',
               machine_type='n1-standard-4',
               accelerator_type=None,
               accelerator_count=0,
               network='',
               auto_scaling=AutoScalingConfig(min_replica_count=1,
                                              max_replica_count=10,
                                              target_accelerator_duty_cycle=60,
                                              scale_down_delay_minutes=5,
                                              enable_scale_to_zero=False),
               traffic_split=None,
               enable_request_logging=True,
               enable_access_logging=True,
               enable_container_logging=True,
               dedicated_endpoint=False,
               spot_instance=False,
               labels={'environment': 'test',
                       'genesis_endpoint': 'true',
                       'genesis_version': '1_0_0',
                       'team': 'ml'})
        endpoint   = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a15a480> is waiting for upstream dependencies to complete.
        labels     = {'environment': 'test',
 'genesis_endpoint': 'true',
 'genesis_version': '1_0_0',
 'team': 'ml'}
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a217320>
        start_time = 1762268315.508436
        sync       = False
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:703: in name
    self._assert_gca_resource_is_available()
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a15a480> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:749: in _assert_gca_resource_is_available
    super()._assert_gca_resource_is_available()
        __class__  = <class 'google.cloud.aiplatform.models.Endpoint'>
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a15a480> is waiting for upstream dependencies to complete.
venv/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:1419: in _assert_gca_resource_is_available
    raise RuntimeError(
E   RuntimeError: Endpoint resource has not been created.
        self       = <google.cloud.aiplatform.models.Endpoint object at 0x78d40a15a480> is waiting for upstream dependencies to complete.
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_endpoints:Creating endpoint: test-endpoint (dedicated=False)
ERROR:vertex_ai.model_endpoints:Endpoint creation failed: Endpoint resource has not been created.
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_endpoints:model_endpoints.py:271 Creating endpoint: test-endpoint (dedicated=False)
ERROR    vertex_ai.model_endpoints:model_endpoints.py:309 Endpoint creation failed: Endpoint resource has not been created.
___________________ test_collect_performance_metrics_success ___________________
tests/vertex/test_monitoring.py:43: in test_collect_performance_metrics_success
    metrics = await monitoring.collect_performance_metrics(
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a164f50>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a164f50>,)
        context    = None
        func       = <function VertexAIMonitoring.collect_performance_metrics at 0x78d40a4ae7a0>
        kwargs     = {'endpoint_id': 'test-endpoint', 'time_window_minutes': 60}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'monitoring.collect_performance_metrics'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/monitoring.py:339: in collect_performance_metrics
    endpoint = Endpoint(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^
E   TypeError: 'NoneType' object is not callable
        endpoint_id = 'test-endpoint'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a164f50>
        time_window_minutes = 60
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
----------------------------- Captured stderr call -----------------------------
ERROR:vertex_ai.monitoring:Failed to load endpoint: 'NoneType' object is not callable
------------------------------ Captured log call -------------------------------
ERROR    vertex_ai.monitoring:monitoring.py:341 Failed to load endpoint: 'NoneType' object is not callable
___________________ test_collect_performance_metrics_latency ___________________
tests/vertex/test_monitoring.py:55: in test_collect_performance_metrics_latency
    metrics = await monitoring.collect_performance_metrics(
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1fe390>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1fe390>,)
        context    = None
        func       = <function VertexAIMonitoring.collect_performance_metrics at 0x78d40a4ae7a0>
        kwargs     = {'endpoint_id': 'latency-endpoint', 'time_window_minutes': 120}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'monitoring.collect_performance_metrics'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/monitoring.py:339: in collect_performance_metrics
    endpoint = Endpoint(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^
E   TypeError: 'NoneType' object is not callable
        endpoint_id = 'latency-endpoint'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1fe390>
        time_window_minutes = 120
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
----------------------------- Captured stderr call -----------------------------
ERROR:vertex_ai.monitoring:Failed to load endpoint: 'NoneType' object is not callable
------------------------------ Captured log call -------------------------------
ERROR    vertex_ai.monitoring:monitoring.py:341 Failed to load endpoint: 'NoneType' object is not callable
_________________ test_collect_performance_metrics_throughput __________________
tests/vertex/test_monitoring.py:71: in test_collect_performance_metrics_throughput
    metrics = await monitoring.collect_performance_metrics(
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1fc140>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1fc140>,)
        context    = None
        func       = <function VertexAIMonitoring.collect_performance_metrics at 0x78d40a4ae7a0>
        kwargs     = {'endpoint_id': 'throughput-endpoint', 'time_window_minutes': 60}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'monitoring.collect_performance_metrics'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/monitoring.py:339: in collect_performance_metrics
    endpoint = Endpoint(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^
E   TypeError: 'NoneType' object is not callable
        endpoint_id = 'throughput-endpoint'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1fc140>
        time_window_minutes = 60
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
----------------------------- Captured stderr call -----------------------------
ERROR:vertex_ai.monitoring:Failed to load endpoint: 'NoneType' object is not callable
------------------------------ Captured log call -------------------------------
ERROR    vertex_ai.monitoring:monitoring.py:341 Failed to load endpoint: 'NoneType' object is not callable
_____________________ test_calculate_cost_metrics_monthly ______________________
tests/vertex/test_monitoring.py:84: in test_calculate_cost_metrics_monthly
    cost_metrics = await monitoring.calculate_cost_metrics(
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1d59a0>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1d59a0>,)
        context    = None
        func       = <function VertexAIMonitoring.calculate_cost_metrics at 0x78d40a4ae8e0>
        kwargs     = {'endpoint_id': 'cost-endpoint', 'period_days': 30}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'monitoring.calculate_cost_metrics'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/monitoring.py:410: in calculate_cost_metrics
    endpoint = Endpoint(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^
E   TypeError: 'NoneType' object is not callable
        endpoint_id = 'cost-endpoint'
        period_days = 30
        period_end = datetime.datetime(2025, 11, 4, 14, 58, 35, 790146)
        period_start = datetime.datetime(2025, 10, 5, 14, 58, 35, 790138)
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1d59a0>
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
----------------------------- Captured stderr call -----------------------------
ERROR:vertex_ai.monitoring:Failed to load endpoint: 'NoneType' object is not callable
------------------------------ Captured log call -------------------------------
ERROR    vertex_ai.monitoring:monitoring.py:412 Failed to load endpoint: 'NoneType' object is not callable
_____________________ test_calculate_cost_metrics_by_model _____________________
tests/vertex/test_monitoring.py:96: in test_calculate_cost_metrics_by_model
    cost_metrics = await monitoring.calculate_cost_metrics(
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a21ce90>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a21ce90>,)
        context    = None
        func       = <function VertexAIMonitoring.calculate_cost_metrics at 0x78d40a4ae8e0>
        kwargs     = {'endpoint_id': 'multi-model-endpoint', 'period_days': 30}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'monitoring.calculate_cost_metrics'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/monitoring.py:410: in calculate_cost_metrics
    endpoint = Endpoint(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^
E   TypeError: 'NoneType' object is not callable
        endpoint_id = 'multi-model-endpoint'
        period_days = 30
        period_end = datetime.datetime(2025, 11, 4, 14, 58, 35, 811236)
        period_start = datetime.datetime(2025, 10, 5, 14, 58, 35, 811228)
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a21ce90>
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
----------------------------- Captured stderr call -----------------------------
ERROR:vertex_ai.monitoring:Failed to load endpoint: 'NoneType' object is not callable
------------------------------ Captured log call -------------------------------
ERROR    vertex_ai.monitoring:monitoring.py:412 Failed to load endpoint: 'NoneType' object is not callable
__________________________ test_check_alerts_success ___________________________
tests/vertex/test_monitoring.py:150: in test_check_alerts_success
    monitoring.add_alert_rule(
E   TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a1668a0>
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
_______________________ test_check_alerts_multiple_rules _______________________
tests/vertex/test_monitoring.py:164: in test_check_alerts_multiple_rules
    monitoring.add_alert_rule(
E   TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a0f4590>
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
_____________________________ test_add_alert_rule ______________________________
tests/vertex/test_monitoring.py:186: in test_add_alert_rule
    monitoring.add_alert_rule(
E   TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d409fe49e0>
        rule_name  = 'test_rule'
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
____________________________ test_remove_alert_rule ____________________________
tests/vertex/test_monitoring.py:201: in test_remove_alert_rule
    monitoring.add_alert_rule(
E   TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a040d10>
        rule_name  = 'removable_rule'
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
______________________ test_model_metrics_initialization _______________________
tests/vertex/test_monitoring.py:228: in test_model_metrics_initialization
    metrics = ModelMetrics(
E   TypeError: ModelMetrics.__init__() got an unexpected keyword argument 'throughput'
_______________________ test_cost_metrics_initialization _______________________
tests/vertex/test_monitoring.py:244: in test_cost_metrics_initialization
    cost = CostMetrics(
E   TypeError: CostMetrics.__init__() got an unexpected keyword argument 'timestamp'
_____________________ test_quality_metrics_initialization ______________________
tests/vertex/test_monitoring.py:259: in test_quality_metrics_initialization
    quality = QualityMetrics(
E   TypeError: QualityMetrics.__init__() got an unexpected keyword argument 'drift_detected'
________________________ test_alert_rule_initialization ________________________
tests/vertex/test_monitoring.py:274: in test_alert_rule_initialization
    rule = AlertRule(
E   TypeError: AlertRule.__init__() got an unexpected keyword argument 'condition'
_____________________________ test_metrics_caching _____________________________
tests/vertex/test_monitoring.py:292: in test_metrics_caching
    metrics1 = await monitoring.collect_performance_metrics(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        endpoint_id = 'cache-test-endpoint'
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a33b5f0>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a33b5f0>,
 'cache-test-endpoint')
        context    = None
        func       = <function VertexAIMonitoring.collect_performance_metrics at 0x78d40a4ae7a0>
        kwargs     = {}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'monitoring.collect_performance_metrics'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/monitoring.py:339: in collect_performance_metrics
    endpoint = Endpoint(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^
E   TypeError: 'NoneType' object is not callable
        endpoint_id = 'cache-test-endpoint'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a33b5f0>
        time_window_minutes = 60
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
----------------------------- Captured stderr call -----------------------------
ERROR:vertex_ai.monitoring:Failed to load endpoint: 'NoneType' object is not callable
------------------------------ Captured log call -------------------------------
ERROR    vertex_ai.monitoring:monitoring.py:341 Failed to load endpoint: 'NoneType' object is not callable
________________________ test_cost_calculation_accuracy ________________________
tests/vertex/test_monitoring.py:303: in test_cost_calculation_accuracy
    cost = await monitoring.calculate_cost_metrics(
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a351c70>
infrastructure/observability.py:711: in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        args       = (<infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a351c70>,)
        context    = None
        func       = <function VertexAIMonitoring.calculate_cost_metrics at 0x78d40a4ae8e0>
        kwargs     = {'endpoint_id': 'billing-endpoint', 'period_days': 30}
        obs_manager = <infrastructure.observability.ObservabilityManager object at 0x78d41f3e4590>
        operation_name = 'monitoring.calculate_cost_metrics'
        span_type  = <SpanType.INFRASTRUCTURE: 'infrastructure'>
infrastructure/vertex_ai/monitoring.py:410: in calculate_cost_metrics
    endpoint = Endpoint(endpoint_id)
               ^^^^^^^^^^^^^^^^^^^^^
E   TypeError: 'NoneType' object is not callable
        endpoint_id = 'billing-endpoint'
        period_days = 30
        period_end = datetime.datetime(2025, 11, 4, 14, 58, 36, 123995)
        period_start = datetime.datetime(2025, 10, 5, 14, 58, 36, 123986)
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a351c70>
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
----------------------------- Captured stderr call -----------------------------
ERROR:vertex_ai.monitoring:Failed to load endpoint: 'NoneType' object is not callable
------------------------------ Captured log call -------------------------------
ERROR    vertex_ai.monitoring:monitoring.py:412 Failed to load endpoint: 'NoneType' object is not callable
_______________________ test_alert_conditions_evaluation _______________________
tests/vertex/test_monitoring.py:317: in test_alert_conditions_evaluation
    monitoring.add_alert_rule(
E   TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
        monitoring = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a32bd10>
---------------------------- Captured stderr setup -----------------------------
INFO:vertex_ai.monitoring:VertexAIMonitoring initialized: project=test-project
------------------------------ Captured log setup ------------------------------
INFO     vertex_ai.monitoring:monitoring.py:311 VertexAIMonitoring initialized: project=test-project
_______ TestVertexAIClientInitialization.test_monitoring_initialization ________
tests/vertex/test_vertex_client.py:43: in test_monitoring_initialization
    monitoring = VertexAIMonitoring(
        self       = <test_vertex_client.TestVertexAIClientInitialization object at 0x78d40a496a20>
infrastructure/vertex_ai/monitoring.py:290: in __init__
    raise ImportError("Vertex AI SDK required")
E   ImportError: Vertex AI SDK required
        location   = 'us-central1'
        project_id = 'test-project'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a338ec0>
______ TestVertexAIEnvironmentHandling.test_credential_handling_mock_mode ______
tests/vertex/test_vertex_client.py:158: in test_credential_handling_mock_mode
    registry = ModelRegistry(
        self       = <test_vertex_client.TestVertexAIEnvironmentHandling object at 0x78d40a4dec30>
infrastructure/vertex_ai/model_registry.py:203: in __init__
    raise ImportError("Vertex AI SDK required: pip install google-cloud-aiplatform")
E   ImportError: Vertex AI SDK required: pip install google-cloud-aiplatform
        location   = 'us-central1'
        metadata_storage_path = None
        project_id = 'test-project'
        self       = <infrastructure.vertex_ai.model_registry.ModelRegistry object at 0x78d40a0408f0>
____________ TestVertexAIIntegration.test_monitoring_with_endpoints ____________
tests/vertex/test_vertex_client.py:189: in test_monitoring_with_endpoints
    monitoring = VertexAIMonitoring(
        endpoints  = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a0409e0>
        self       = <test_vertex_client.TestVertexAIIntegration object at 0x78d40a4df050>
infrastructure/vertex_ai/monitoring.py:290: in __init__
    raise ImportError("Vertex AI SDK required")
E   ImportError: Vertex AI SDK required
        location   = 'us-central1'
        project_id = 'test-project'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a043020>
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=test-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=test-project, location=us-central1
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=test-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=test-project, location=us-central1
___________ TestVertexAIIntegration.test_all_components_same_project ___________
tests/vertex/test_vertex_client.py:217: in test_all_components_same_project
    monitoring = VertexAIMonitoring(project_id=project_id, location=location)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        endpoints  = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a042cc0>
        location   = 'us-central1'
        project_id = 'unified-project'
        registry   = <infrastructure.vertex_ai.model_registry.ModelRegistry object at 0x78d40a042fc0>
        self       = <test_vertex_client.TestVertexAIIntegration object at 0x78d40a4df470>
infrastructure/vertex_ai/monitoring.py:290: in __init__
    raise ImportError("Vertex AI SDK required")
E   ImportError: Vertex AI SDK required
        location   = 'us-central1'
        project_id = 'unified-project'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a040b30>
----------------------------- Captured stderr call -----------------------------
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=unified-project, location=us-central1
INFO:vertex_ai.model_registry:Loaded 3 models from cache
INFO:vertex_ai.model_registry:ModelRegistry initialized: project=unified-project, location=us-central1
INFO:vertex_ai.model_endpoints:ModelEndpoints initialized: project=unified-project, location=us-central1
------------------------------ Captured log call -------------------------------
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=unified-project, location=us-central1
INFO     vertex_ai.model_registry:model_registry.py:232 Loaded 3 models from cache
INFO     vertex_ai.model_registry:model_registry.py:219 ModelRegistry initialized: project=unified-project, location=us-central1
INFO     vertex_ai.model_endpoints:model_endpoints.py:241 ModelEndpoints initialized: project=unified-project, location=us-central1
_____________ TestVertexAIFallbackBehavior.test_mock_mode_fallback _____________
tests/vertex/test_vertex_client.py:232: in test_mock_mode_fallback
    registry = ModelRegistry(
        self       = <test_vertex_client.TestVertexAIFallbackBehavior object at 0x78d40a4df6b0>
infrastructure/vertex_ai/model_registry.py:203: in __init__
    raise ImportError("Vertex AI SDK required: pip install google-cloud-aiplatform")
E   ImportError: Vertex AI SDK required: pip install google-cloud-aiplatform
        location   = 'us-central1'
        metadata_storage_path = None
        project_id = 'test-project'
        self       = <infrastructure.vertex_ai.model_registry.ModelRegistry object at 0x78d40a041eb0>
________ TestVertexAIFallbackBehavior.test_monitoring_without_real_api _________
tests/vertex/test_vertex_client.py:241: in test_monitoring_without_real_api
    monitoring = VertexAIMonitoring(
        self       = <test_vertex_client.TestVertexAIFallbackBehavior object at 0x78d40a4df8c0>
infrastructure/vertex_ai/monitoring.py:290: in __init__
    raise ImportError("Vertex AI SDK required")
E   ImportError: Vertex AI SDK required
        location   = 'us-central1'
        project_id = 'test-project'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a040890>
__________ TestVertexAIFallbackBehavior.test_endpoints_degraded_mode ___________
tests/vertex/test_vertex_client.py:250: in test_endpoints_degraded_mode
    endpoints = ModelEndpoints(
        self       = <test_vertex_client.TestVertexAIFallbackBehavior object at 0x78d40a4dfad0>
infrastructure/vertex_ai/model_endpoints.py:223: in __init__
    raise ImportError("Vertex AI SDK required: pip install google-cloud-aiplatform")
E   ImportError: Vertex AI SDK required: pip install google-cloud-aiplatform
        location   = 'us-central1'
        model_registry = None
        project_id = 'test-project'
        self       = <infrastructure.vertex_ai.model_endpoints.ModelEndpoints object at 0x78d40a042450>
__________ TestVertexAICostTracking.test_cost_metrics_initialization ___________
tests/vertex/test_vertex_client.py:262: in test_cost_metrics_initialization
    monitoring = VertexAIMonitoring(
        self       = <test_vertex_client.TestVertexAICostTracking object at 0x78d40a4dfd40>
infrastructure/vertex_ai/monitoring.py:290: in __init__
    raise ImportError("Vertex AI SDK required")
E   ImportError: Vertex AI SDK required
        location   = 'us-central1'
        project_id = 'test-project'
        self       = <infrastructure.vertex_ai.monitoring.VertexAIMonitoring object at 0x78d40a043530>
=========================== short test summary info ============================
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_prepare_se_darwin_dataset_success - ValueError: No valid training examples found in /tmp/tmpntaqgh8s/archive.json
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_prepare_se_darwin_dataset_filtering - ValueError: No valid training examples found in /tmp/tmpnedlppbr/archive-filtered.json
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_prepare_halo_routing_dataset_success - ValueError: No valid routing decisions found in /tmp/tmpqlbvh8ac/routing-decisions.jsonl
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_prepare_halo_routing_dataset_validation - ValueError: No valid routing decisions found in /tmp/tmphim_kmrn/routing-valid.jsonl
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_supervised - RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_rlhf - RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_distillation - RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_submit_tuning_job_parameter_efficient - RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_register_tuned_model_success - google.api_core.exceptions.PermissionDenied: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_register_tuned_model_with_metadata - google.api_core.exceptions.PermissionDenied: 403 Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: "SERVICE_DISABLED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "aiplatform.googleapis.com"
}
metadata {
  key: "serviceTitle"
  value: "Vertex AI API"
}
metadata {
  key: "containerInfo"
  value: "test-project"
}
metadata {
  key: "consumer"
  value: "projects/test-project"
}
metadata {
  key: "activationUrl"
  value: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
, locale: "en-US"
message: "Vertex AI API has not been used in project test-project before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry."
, links {
  description: "Google developers console API activation"
  url: "https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=test-project"
}
]
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_tuning_with_custom_hyperparameters - RuntimeError: staging_bucket should be passed to CustomJob.from_local_script or should be set using aiplatform.init(staging_bucket='gs://my-bucket')
FAILED tests/vertex/test_fine_tuning_pipeline.py::test_dataset_preparation_with_validation_split - ValueError: No valid training examples found in /tmp/tmpo_fowe9z/archive-split.json
FAILED tests/vertex/test_model_endpoints.py::test_create_endpoint_success - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_create_endpoint_with_network - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_deploy_model_success - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_deploy_model_with_autoscaling - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_predict_success - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_predict_batch - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_update_traffic_split_ab_testing - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_update_traffic_split_gradual_rollout - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_undeploy_model - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_delete_endpoint - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_list_endpoints - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_list_endpoints_with_filters - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_get_endpoint_stats - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_model_endpoints.py::test_predict_with_custom_parameters - RuntimeError: Endpoint resource has not been created.
FAILED tests/vertex/test_monitoring.py::test_collect_performance_metrics_success - TypeError: 'NoneType' object is not callable
FAILED tests/vertex/test_monitoring.py::test_collect_performance_metrics_latency - TypeError: 'NoneType' object is not callable
FAILED tests/vertex/test_monitoring.py::test_collect_performance_metrics_throughput - TypeError: 'NoneType' object is not callable
FAILED tests/vertex/test_monitoring.py::test_calculate_cost_metrics_monthly - TypeError: 'NoneType' object is not callable
FAILED tests/vertex/test_monitoring.py::test_calculate_cost_metrics_by_model - TypeError: 'NoneType' object is not callable
FAILED tests/vertex/test_monitoring.py::test_check_alerts_success - TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
FAILED tests/vertex/test_monitoring.py::test_check_alerts_multiple_rules - TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
FAILED tests/vertex/test_monitoring.py::test_add_alert_rule - TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
FAILED tests/vertex/test_monitoring.py::test_remove_alert_rule - TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
FAILED tests/vertex/test_monitoring.py::test_model_metrics_initialization - TypeError: ModelMetrics.__init__() got an unexpected keyword argument 'throughput'
FAILED tests/vertex/test_monitoring.py::test_cost_metrics_initialization - TypeError: CostMetrics.__init__() got an unexpected keyword argument 'timestamp'
FAILED tests/vertex/test_monitoring.py::test_quality_metrics_initialization - TypeError: QualityMetrics.__init__() got an unexpected keyword argument 'drift_detected'
FAILED tests/vertex/test_monitoring.py::test_alert_rule_initialization - TypeError: AlertRule.__init__() got an unexpected keyword argument 'condition'
FAILED tests/vertex/test_monitoring.py::test_metrics_caching - TypeError: 'NoneType' object is not callable
FAILED tests/vertex/test_monitoring.py::test_cost_calculation_accuracy - TypeError: 'NoneType' object is not callable
FAILED tests/vertex/test_monitoring.py::test_alert_conditions_evaluation - TypeError: VertexAIMonitoring.add_alert_rule() got an unexpected keyword argument 'rule_name'
FAILED tests/vertex/test_vertex_client.py::TestVertexAIClientInitialization::test_monitoring_initialization - ImportError: Vertex AI SDK required
FAILED tests/vertex/test_vertex_client.py::TestVertexAIEnvironmentHandling::test_credential_handling_mock_mode - ImportError: Vertex AI SDK required: pip install google-cloud-aiplatform
FAILED tests/vertex/test_vertex_client.py::TestVertexAIIntegration::test_monitoring_with_endpoints - ImportError: Vertex AI SDK required
FAILED tests/vertex/test_vertex_client.py::TestVertexAIIntegration::test_all_components_same_project - ImportError: Vertex AI SDK required
FAILED tests/vertex/test_vertex_client.py::TestVertexAIFallbackBehavior::test_mock_mode_fallback - ImportError: Vertex AI SDK required: pip install google-cloud-aiplatform
FAILED tests/vertex/test_vertex_client.py::TestVertexAIFallbackBehavior::test_monitoring_without_real_api - ImportError: Vertex AI SDK required
FAILED tests/vertex/test_vertex_client.py::TestVertexAIFallbackBehavior::test_endpoints_degraded_mode - ImportError: Vertex AI SDK required: pip install google-cloud-aiplatform
FAILED tests/vertex/test_vertex_client.py::TestVertexAICostTracking::test_cost_metrics_initialization - ImportError: Vertex AI SDK required
!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 50 failures !!!!!!!!!!!!!!!!!!!!!!!!!!
================== 50 failed, 37 passed, 57 warnings in 6.49s ==================

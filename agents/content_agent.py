"""
CONTENT AGENT - Microsoft Agent Framework Version
Version: 4.0 (Enhanced with DAAO + TUMIX)

Generates blog posts, documentation, and content marketing materials.
Enhanced with:
- DAAO routing (20-30% cost reduction on varied complexity tasks)
- TUMIX early termination (50-60% cost reduction on iterative content refinement)
"""

import json
import logging
from datetime import datetime
from typing import List, Dict
from agent_framework import ChatAgent
from agent_framework.azure import AzureAIAgentClient
from agent_framework.observability import setup_observability
from azure.identity.aio import AzureCliCredential

# Import DAAO and TUMIX
from infrastructure.daao_router import get_daao_router, RoutingDecision
from infrastructure.tumix_termination import (
    get_tumix_termination,
    RefinementResult,
    TerminationDecision
)

# Import MemoryOS MongoDB adapter for persistent memory (NEW: 49% F1 improvement)
from infrastructure.memory_os_mongodb_adapter import (
    GenesisMemoryOSMongoDB,
    create_genesis_memory_mongodb
)

# Import WebVoyager for web navigation and content research (optional - graceful fallback)
try:
    from infrastructure.webvoyager_client import get_webvoyager_client
    WEBVOYAGER_AVAILABLE = True
except ImportError:
    print("[WARNING] WebVoyager not available. Web navigation features will be disabled.")
    WEBVOYAGER_AVAILABLE = False
    get_webvoyager_client = None

setup_observability(enable_sensitive_data=True)
logger = logging.getLogger(__name__)


class ContentAgent:
    """
    Content creation and documentation specialist

    Enhanced with:
    - DAAO: Routes simple content to cheap models, complex long-form to premium
    - TUMIX: Stops iterative refinement when content quality plateaus (saves 50-60%)
    """

    def __init__(self, business_id: str = "default"):
        self.business_id = business_id
        self.agent = None

        # Initialize DAAO router for cost optimization
        self.router = get_daao_router()

        # Initialize TUMIX for iterative content refinement
        # Content benefits from more refinement: min 2, max 5 rounds
        self.termination = get_tumix_termination(
            min_rounds=2,  # Draft + first revision minimum
            max_rounds=5,  # Content benefits from more refinement
            improvement_threshold=0.05  # 5% improvement threshold (standard)
        )

        # Track refinement sessions for metrics
        self.refinement_history: List[List[RefinementResult]] = []

        # Initialize MemoryOS MongoDB adapter for persistent memory (NEW: 49% F1 improvement)
        # Enables content style memory, topic expertise tracking, brand voice consistency
        self.memory: Optional[GenesisMemoryOSMongoDB] = None
        self._init_memory()

        # Initialize WebVoyager client for web content research (NEW: 59.1% success rate)
        if WEBVOYAGER_AVAILABLE:
            self.webvoyager = get_webvoyager_client(
                headless=True,
                max_iterations=15,
                text_only=False  # Use multimodal (screenshots + GPT-4V)
            )
        else:
            self.webvoyager = None

        logger.info(f"Content Agent v4.0 initialized with DAAO + TUMIX + MemoryOS + WebVoyager for business: {business_id}")

    async def initialize(self):
        cred = AzureCliCredential()
        client = AzureAIAgentClient(async_credential=cred)

        tools = [self.write_blog_post, self.create_documentation, self.generate_faq]

        # Add web_content_research tool if WebVoyager is available
        if WEBVOYAGER_AVAILABLE and self.webvoyager:
            tools.append(self.web_content_research)

        self.agent = ChatAgent(
            chat_client=client,
            instructions="You are an expert content writer specializing in technical documentation and blog posts. Create engaging, SEO-optimized content. For tasks requiring web-based content research (competitor content analysis, trend monitoring, social media research), use the web_content_research tool which employs a multimodal web agent with 59.1% success rate to navigate real websites and extract content.",
            name="content-agent",
            tools=tools
        )
        print(f"ğŸ“ Content Agent initialized for business: {self.business_id}")
        print(f"   - MemoryOS MongoDB backend enabled (49% F1 improvement)")
        if WEBVOYAGER_AVAILABLE and self.webvoyager:
            print(f"   - WebVoyager web navigation enabled (59.1% success rate)\n")
        else:
            print(f"   - WebVoyager: NOT AVAILABLE (install dependencies)\n")

    def _init_memory(self):
        """Initialize MemoryOS MongoDB backend for Content creation memory."""
        try:
            import os
            self.memory = create_genesis_memory_mongodb(
                mongodb_uri=os.getenv("MONGODB_URI", "mongodb://localhost:27017/"),
                database_name="genesis_memory_content",
                short_term_capacity=10,  # Recent content pieces
                mid_term_capacity=600,   # Historical content styles (Content-specific)
                long_term_knowledge_capacity=250  # Brand voice, topic expertise, style preferences
            )
            logger.info("[ContentAgent] MemoryOS MongoDB initialized for content style/topic tracking")
        except Exception as e:
            logger.warning(f"[ContentAgent] Failed to initialize MemoryOS: {e}. Memory features disabled.")
            self.memory = None

    def write_blog_post(self, title: str, keywords: List[str], word_count: int = 1000) -> str:
        """
        Generate blog post outline with SEO optimization.

        NEW: MemoryOS integration - Retrieves similar content styles and stores brand voice patterns
        for consistency (49% F1 improvement on content quality).
        """
        user_id = f"content_{self.business_id}"

        # Retrieve historical content style patterns from memory
        historical_context = ""
        if self.memory:
            try:
                memories = self.memory.retrieve(
                    agent_id="content",
                    user_id=user_id,
                    query=f"blog post {title} {' '.join(keywords[:3])}",
                    memory_type=None,
                    top_k=3
                )
                if memories:
                    historical_context = "\n".join([
                        f"- Previous content: {m['content'].get('agent_response', '')}"
                        for m in memories
                    ])
                    logger.info(f"[ContentAgent] Retrieved {len(memories)} similar content patterns from memory")
            except Exception as e:
                logger.warning(f"[ContentAgent] Memory retrieval failed: {e}")

        sections = [
            {"heading": "Introduction", "words": int(word_count * 0.15)},
            {"heading": "Main Content Part 1", "words": int(word_count * 0.25)},
            {"heading": "Main Content Part 2", "words": int(word_count * 0.25)},
            {"heading": "Best Practices", "words": int(word_count * 0.20)},
            {"heading": "Conclusion", "words": int(word_count * 0.15)}
        ]

        result = {
            "title": title,
            "keywords": keywords,
            "sections": sections,
            "word_count": word_count,
            "historical_context": historical_context if historical_context else "No similar content found"
        }

        # Store content creation in memory for future reference
        if self.memory:
            try:
                self.memory.store(
                    agent_id="content",
                    user_id=user_id,
                    user_input=f"Write blog post: {title}",
                    agent_response=f"Created {len(sections)}-section blog post ({word_count} words) with keywords: {', '.join(keywords[:5])}",
                    memory_type="conversation"
                )
                logger.info(f"[ContentAgent] Stored content creation in memory: {title}")
            except Exception as e:
                logger.warning(f"[ContentAgent] Memory storage failed: {e}")

        return json.dumps(result, indent=2)

    def create_documentation(self, product_name: str, sections: List[str]) -> str:
        """Generate technical documentation structure"""
        docs = {section: f"Documentation for {section} in {product_name}" for section in sections}
        return json.dumps({"product": product_name, "docs": docs, "sections": len(sections)})

    def generate_faq(self, product_name: str, num_questions: int = 10) -> str:
        """Generate FAQ questions and answers"""
        faqs = [{"q": f"Question {i} about {product_name}?", "a": f"Answer {i}"} for i in range(1, num_questions + 1)]
        return json.dumps({"product": product_name, "faqs": faqs, "count": len(faqs)})

    def route_task(self, task_description: str, priority: float = 0.5) -> RoutingDecision:
        """
        Route content task to appropriate model using DAAO

        Args:
            task_description: Description of the content task
            priority: Task priority (0.0-1.0)

        Returns:
            RoutingDecision with model selection and cost estimate
        """
        task = {
            'id': f'content-{datetime.now().strftime("%Y%m%d%H%M%S")}',
            'description': task_description,
            'priority': priority,
            'required_tools': []
        }

        decision = self.router.route_task(task, budget_conscious=True)

        logger.info(
            f"Content task routed: {decision.reasoning}",
            extra={
                'agent': 'ContentAgent',
                'model': decision.model,
                'difficulty': decision.difficulty.value,
                'estimated_cost': decision.estimated_cost
            }
        )

        return decision

    def get_cost_metrics(self) -> Dict:
        """Get cumulative cost savings from DAAO and TUMIX"""
        if not self.refinement_history:
            return {
                'agent': 'ContentAgent',
                'tumix_sessions': 0,
                'tumix_savings_percent': 0.0,
                'message': 'No refinement sessions recorded yet'
            }

        tumix_savings = self.termination.estimate_cost_savings(
            [
                [r for r in session]
                for session in self.refinement_history
            ],
            cost_per_round=0.001
        )

        return {
            'agent': 'ContentAgent',
            'tumix_sessions': tumix_savings['sessions'],
            'tumix_baseline_rounds': tumix_savings['baseline_rounds'],
            'tumix_actual_rounds': tumix_savings['tumix_rounds'],
            'tumix_savings_percent': tumix_savings['savings_percent'],
            'tumix_total_saved': tumix_savings['savings'],
            'daao_info': 'DAAO routing automatically applied to all tasks'
        }

    async def web_content_research(
        self,
        url: str,
        task: str,
        save_screenshots: bool = True
    ) -> str:
        """
        Perform web content research using WebVoyager multimodal agent (NEW: 59.1% success rate).

        This method employs a multimodal web agent for content marketing research tasks like
        competitor content analysis, trend monitoring, social media research, and blog content
        extraction. Ideal for researching content topics, analyzing competitor strategies, and
        extracting inspiration from successful web content.

        Args:
            url: Starting website URL (e.g., "https://www.medium.com")
            task: Natural language task description
                Examples:
                - "Find top 5 AI articles on Medium and extract titles, authors, and engagement metrics"
                - "Navigate to competitor blog and extract latest 3 post titles and topics"
                - "Search Twitter for trending hashtags about AI and summarize top 10 posts"
            save_screenshots: Whether to save trajectory screenshots

        Returns:
            JSON string containing web content research results with metadata

        Example:
            ```python
            result = await content.web_content_research(
                url="https://www.medium.com",
                task="Find trending AI articles and extract titles and topics for blog inspiration"
            )
            ```

        Performance:
        - 59.1% success rate on diverse web tasks (WebVoyager benchmark)
        - Ideal for content research, competitor analysis, trend monitoring
        - 30-50% faster than manual web content research
        """
        import time
        import json
        from datetime import datetime

        if not WEBVOYAGER_AVAILABLE or not self.webvoyager:
            logger.error("WebVoyager not available. Cannot perform web content research.")
            return json.dumps({
                "research_id": f"WEB-ERROR-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "url": url,
                "task": task,
                "error": "WebVoyager not available. Install WebVoyager dependencies.",
                "status": "unavailable"
            }, indent=2)

        start_time = time.time()

        logger.info(f"Starting web content research: url='{url}', task='{task}'")

        try:
            # Configure output directory
            output_dir = None
            if save_screenshots:
                output_dir = f"/tmp/webvoyager_content_{self.business_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            # Execute web navigation task
            result = await self.webvoyager.navigate_and_extract(
                url=url,
                task=task,
                output_dir=output_dir
            )

            elapsed_time = time.time() - start_time

            logger.info(
                f"Web content research {'completed' if result['success'] else 'failed'}: "
                f"iterations={result['iterations']}, "
                f"screenshots={len(result['screenshots'])}, "
                f"time={elapsed_time:.2f}s"
            )

            # Format result for tool output
            result_dict = {
                "research_id": f"WEB-CONTENT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "url": url,
                "task": task,
                "success": result['success'],
                "content_extracted": result['answer'],
                "trajectory": result['trajectory'],
                "metadata": {
                    "iterations": result['iterations'],
                    "screenshots_saved": len(result['screenshots']),
                    "screenshot_dir": output_dir if save_screenshots else None,
                    "elapsed_time_sec": elapsed_time,
                    "timestamp": datetime.now().isoformat(),
                    "final_url": result['trajectory'][-1]['url'] if result['trajectory'] else url,
                    "error": result.get('error')
                }
            }

            # Store web content research in memory for pattern tracking
            if self.memory:
                try:
                    self.memory.store(
                        agent_id="content",
                        user_id=f"content_{self.business_id}",
                        user_message=f"Web content research: {task}",
                        agent_response=result['answer'],
                        context={
                            "url": url,
                            "task": task,
                            "success": result['success'],
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    logger.info("[ContentAgent] Stored web content research in MemoryOS")
                except Exception as e:
                    logger.warning(f"[ContentAgent] Failed to store web content research in memory: {e}")

            return json.dumps(result_dict, indent=2)

        except Exception as e:
            logger.error(f"Web content research failed: {e}", exc_info=True)
            return json.dumps({
                "research_id": f"WEB-CONTENT-ERROR-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                "url": url,
                "task": task,
                "error": str(e),
                "status": "failed"
            }, indent=2)


async def get_content_agent(business_id: str = "default") -> ContentAgent:
    agent = ContentAgent(business_id=business_id)
    await agent.initialize()
    return agent
